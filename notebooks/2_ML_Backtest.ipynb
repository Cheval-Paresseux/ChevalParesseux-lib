{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import Data as dt\n",
    "import ChevalParesseux_lib as lib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **I. Preparation**\n",
    "- Loading data\n",
    "- Initializing strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== I. Load data =====\n",
    "data = dt.load_dataList(ticker_list=['A', 'AAPL', 'GME', 'META'])\n",
    "\n",
    "# ===== II. Making Samples =====\n",
    "training_data = {}\n",
    "testing_data = {}\n",
    "embargo_data = {}\n",
    "\n",
    "for ticker in data.keys():\n",
    "    full_df = data[ticker].copy()\n",
    "    full_df.index = pd.to_datetime(full_df['date'])\n",
    "    training_data[ticker] = full_df.loc['2005-01-01':'2019-01-01']\n",
    "    testing_data[ticker] = full_df.loc['2019-01-01': '2023-01-01']\n",
    "    embargo_data[ticker] = full_df.loc['2023-01-01':]\n",
    "\n",
    "full_training_data = pd.concat([training_data[ticker] for ticker in training_data.keys()], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== I. Define auxiliary parameters =====\n",
    "non_feature_columns = ['date', 'code', 'exchange', 'open', 'high', 'low', 'close', 'volume', 'count_trx', 'label']\n",
    "price_name = 'close'\n",
    "date_name = 'date'\n",
    "bid_open_name = 'open'\n",
    "ask_open_name = 'open'\n",
    "n_jobs = 9\n",
    "\n",
    "# ===== II. Initialize ML strategy =====\n",
    "strategy = lib.ML_strategy(n_jobs=n_jobs, date_name=date_name, bid_open_name=bid_open_name, ask_open_name=ask_open_name)\n",
    "strategy = strategy.set_params(non_feature_columns=non_feature_columns, price_name=price_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **II. Get Training Data**\n",
    "- Apply Resampling/Labelling/Features\n",
    "- Generate Folds and Rebalanced training set\n",
    "- Apply features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== I. Define the models to extract Training Data =====\n",
    "sampling_model = lib.DataSampler\n",
    "labeller_model = lib.tripleBarrier_labeller\n",
    "features_model = [\n",
    "    lib.average_feature, \n",
    "    lib.minimum_feature, \n",
    "    lib.volatility_feature, \n",
    "    lib.quantile_feature, \n",
    "    lib.Z_momentum_feature, \n",
    "    lib.nonlinear_tempReg_feature, \n",
    "    lib.hurst_exponent_feature\n",
    "]\n",
    "cleaner_model = lib.FeaturesCleaner\n",
    "\n",
    "# ===== II. Set the models to the strategy =====\n",
    "strategy = strategy.set_models(\n",
    "    sampling_model=sampling_model,\n",
    "    labeller_model=labeller_model,\n",
    "    features_model=features_model,\n",
    "    cleaner_model=cleaner_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== III. Set the parameters for the models =====\n",
    "sampling_params = {\n",
    "    \"sampling_method\": \"daily_volBars\",\n",
    "    \"column_name\": \"volume\",\n",
    "    \"grouping_column\": \"code\",\n",
    "    \"new_cols_methods\": \"mean\",\n",
    "    \"vol_threshold\": 0.005,\n",
    "    \"aggregation_dict\": {\n",
    "        \"open\": \"first\",\n",
    "        \"high\": \"max\",\n",
    "        \"low\": \"min\",\n",
    "        \"close\": \"last\",\n",
    "        \"volume\": \"sum\",\n",
    "        \"date\": \"first\",\n",
    "        \"code\": \"first\",\n",
    "        \"exchange\": \"first\",\n",
    "        \"count_trx\": \"sum\",\n",
    "    }\n",
    "}\n",
    "labeller_params = {\n",
    "    \"upper_barrier\": [1],\n",
    "    \"lower_barrier\": [1.5],\n",
    "    \"vertical_barrier\": [20],\n",
    "    \"vol_window\": [20],\n",
    "    \"smoothing_method\": [\"ewma\"],\n",
    "    \"window_smooth\": [5],\n",
    "    \"lambda_smooth\": [0.2],\n",
    "}\n",
    "features_params = {\n",
    "    \"window\": [5, 10, 30, 60, 120],\n",
    "    \"power\": [3, 4, 5],\n",
    "    \"quantile\": [0.1, 0.9],\n",
    "    \"smoothing_method\": [None, \"ewma\"],\n",
    "    \"window_smooth\": [10],\n",
    "    \"lambda_smooth\": [0.2],\n",
    "}\n",
    "cleaner_params = {\n",
    "    'stationarity_threshold': 0.05,\n",
    "    'outliers_threshold': 5,\n",
    "}\n",
    "\n",
    "# ===== IV. Set the parameters to the strategy =====\n",
    "strategy = strategy.set_params(\n",
    "    sampling_params=sampling_params,\n",
    "    labeller_params=labeller_params,\n",
    "    features_params=features_params,\n",
    "    cleaner_params=cleaner_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelling data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:27<00:00, 51.86s/it]\n"
     ]
    }
   ],
   "source": [
    "# ===== V. Set the data to the strategy =====\n",
    "stacked_data, processed_data, features_informations = strategy.get_training_data(training_data=full_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== I. Define Model for Rebalancing =====\n",
    "splitSample_model = lib.TemporalUniquenessSplitter\n",
    "splitSample_params = {\n",
    "    'labels_name': \"label\",\n",
    "    'price_name': \"close\",\n",
    "    'n_samples': 2000,\n",
    "    'replacement': False,\n",
    "    'vol_window': 20,\n",
    "    'upper_barrier': 1,\n",
    "    'vertical_barrier': 20,\n",
    "}\n",
    "\n",
    "# ===== II. Set the model to the strategy =====\n",
    "strategy = strategy.set_models(splitSample_model=splitSample_model)\n",
    "strategy = strategy.set_params(splitSample_params=splitSample_params)\n",
    "\n",
    "# ===== III. Get the rebalancing data =====\n",
    "n_folds = 5\n",
    "random_state = 42\n",
    "folds, balanced_folds = strategy.split_and_resample(df=stacked_data, n_folds=n_folds, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== I. Define Model for Feature Selection =====\n",
    "featuresSelector_model = lib.NoCorrelationSelector\n",
    "featuresSelector_params = {'correlation_threshold': 0.9}\n",
    "\n",
    "# ===== II. Set the model to the strategy =====\n",
    "strategy = strategy.set_models(featuresSelector_model=featuresSelector_model)\n",
    "strategy = strategy.set_params(featuresSelector_params=featuresSelector_params)\n",
    "\n",
    "# ===== III. Get the features selection data =====\n",
    "training_df = strategy.features_selection(training_df=stacked_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **III. Train Core Models**\n",
    "- Tune Hyperparameters of the predictor\n",
    "- Fit the predictor\n",
    "- Calibrate the Meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== I. Define Model for Predictor Tuning =====\n",
    "predictor_model = lib.skLearnTreeClassifier\n",
    "\n",
    "splitSample_model = lib.TemporalUniquenessSplitter\n",
    "splitSample_params = {\n",
    "    'labels_name': \"label\",\n",
    "    'price_name': \"close\",\n",
    "    'n_samples': 5000,\n",
    "    'replacement': True,\n",
    "    'vol_window': 20,\n",
    "    'upper_barrier': 1,\n",
    "    'vertical_barrier': 20,\n",
    "}\n",
    "\n",
    "gridSearch_model = lib.linearCV_GridSearch\n",
    "gridSearch_params = {\n",
    "    \"criteria\": \"f1_score\", \n",
    "    \"n_folds\": 5, \n",
    "    \"balanced_training\": False\n",
    "}\n",
    "\n",
    "gridUniverse = {\n",
    "    'criterion': ['log_loss'],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [2],\n",
    "    'max_features': ['sqrt'],\n",
    "    'ccp_alpha': [0.0],\n",
    "    'class_weight': [None]\n",
    "}\n",
    "\n",
    "# ===== II. Set the models to the strategy =====\n",
    "strategy = strategy.set_models(\n",
    "    predictor_model=predictor_model,\n",
    "    splitSample_model=splitSample_model,\n",
    "    gridSearch_model=gridSearch_model\n",
    ")\n",
    "strategy = strategy.set_params(\n",
    "    splitSample_params=splitSample_params,\n",
    "    gridSearch_params=gridSearch_params,\n",
    "    gridUniverse=gridUniverse\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score : 0.6175729103542587 for params : {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'ccp_alpha': 0.0, 'class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "# ===== III. Tune the predictor Hyperparameters =====\n",
    "best_params = strategy.tune_predictor(training_df=training_df)\n",
    "\n",
    "# ===== IV. Fit the Predictor =====\n",
    "strategy = strategy.fit(training_df=training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 109 features, but DecisionTreeClassifier is expecting 91 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m strategy = strategy.set_params(metaGridUniverse=metaGridUnivers)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# ===== III. Get the meta model data =====\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m profit_history = \u001b[43mstrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtune_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosts\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/ChevalParesseux-lib/notebooks/../ChevalParesseux_lib/Strategy_Testing/StrategyBacktest/strategies.py:453\u001b[39m, in \u001b[36mML_strategy.tune_meta\u001b[39m\u001b[34m(self, processed_data, costs)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m.metrics = [] \u001b[38;5;66;03m# Reset the metrics for each backtest, they are computed each time we call get_signals\u001b[39;00m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m processed_data:\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m     df_ops = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df_ops.empty:\n\u001b[32m    455\u001b[39m         results.append(df_ops)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/ChevalParesseux-lib/notebooks/../ChevalParesseux_lib/Strategy_Testing/StrategyBacktest/strategies.py:581\u001b[39m, in \u001b[36mML_strategy.predict\u001b[39m\u001b[34m(self, df)\u001b[39m\n\u001b[32m    578\u001b[39m y_test = results_df[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m].copy()\n\u001b[32m    580\u001b[39m \u001b[38;5;66;03m# ======= II. Make Predictions =======\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    582\u001b[39m predictions = pd.Series(predictions, index=X_test.index)\n\u001b[32m    584\u001b[39m \u001b[38;5;66;03m# ======= III. Filter the Signals =======\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/ChevalParesseux-lib/notebooks/../ChevalParesseux_lib/Model_Training/Models/sklearn_wrappers.py:122\u001b[39m, in \u001b[36mskLearnTreeClassifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[33;03mPredict the labels for the given data.\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03mParameters:\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[33;03m    - X (pd.DataFrame): The data to be predicted.\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m X_test = np.array(X)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m preds_probas = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecision_tree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# Align predicted indices with actual class labels\u001b[39;00m\n\u001b[32m    125\u001b[39m class_order = \u001b[38;5;28mself\u001b[39m.decision_tree.classes_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/testEnv/lib/python3.11/site-packages/sklearn/tree/_classes.py:1057\u001b[39m, in \u001b[36mDecisionTreeClassifier.predict_proba\u001b[39m\u001b[34m(self, X, check_input)\u001b[39m\n\u001b[32m   1033\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Predict class probabilities of the input samples X.\u001b[39;00m\n\u001b[32m   1034\u001b[39m \n\u001b[32m   1035\u001b[39m \u001b[33;03mThe predicted class probability is the fraction of samples of the same\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1054\u001b[39m \u001b[33;03m    classes corresponds to that in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[32m   1055\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1056\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1058\u001b[39m proba = \u001b[38;5;28mself\u001b[39m.tree_.predict(X)\n\u001b[32m   1060\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/testEnv/lib/python3.11/site-packages/sklearn/tree/_classes.py:489\u001b[39m, in \u001b[36mBaseDecisionTree._validate_X_predict\u001b[39m\u001b[34m(self, X, check_input)\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    488\u001b[39m     ensure_all_finite = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    498\u001b[39m     X.indices.dtype != np.intc \u001b[38;5;129;01mor\u001b[39;00m X.indptr.dtype != np.intc\n\u001b[32m    499\u001b[39m ):\n\u001b[32m    500\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/testEnv/lib/python3.11/site-packages/sklearn/utils/validation.py:2965\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2962\u001b[39m     out = X, y\n\u001b[32m   2964\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2965\u001b[39m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2967\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/testEnv/lib/python3.11/site-packages/sklearn/utils/validation.py:2829\u001b[39m, in \u001b[36m_check_n_features\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2826\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2828\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_features != estimator.n_features_in_:\n\u001b[32m-> \u001b[39m\u001b[32m2829\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2830\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2831\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.n_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features as input.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2832\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: X has 109 features, but DecisionTreeClassifier is expecting 91 features as input."
     ]
    }
   ],
   "source": [
    "# ===== I. Define Meta Model =====\n",
    "meta_model = lib.noFilter\n",
    "metaGridUnivers = {}\n",
    "\n",
    "# ===== II. Set the models to the strategy =====\n",
    "strategy = strategy.set_models(meta_model=meta_model)\n",
    "strategy = strategy.set_params(metaGridUniverse=metaGridUnivers)\n",
    "\n",
    "# ===== III. Get the meta model data =====\n",
    "profit_history = strategy.tune_meta(processed_data=processed_data, costs=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
