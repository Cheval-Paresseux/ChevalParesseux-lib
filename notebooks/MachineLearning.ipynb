{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import Data as dt #! this module is not available in the repository, you can use whatever data you have\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "from abc import ABC, abstractmethod\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ==================================================================================== #\n",
    "#! ================================== Series Filters ================================== #\n",
    "def moving_average(\n",
    "    price_series: pd.Series,\n",
    "    window: int,\n",
    "):\n",
    "    # ======= I. Compute the moving average =======\n",
    "    moving_avg = price_series.rolling(window=window + 1).mean()\n",
    "\n",
    "    # ======= II. Convert to pd.Series and Normalize =======\n",
    "    moving_avg = pd.Series(moving_avg, index=price_series.index) / (price_series + 1e-8)\n",
    "\n",
    "    return moving_avg\n",
    "\n",
    "#*____________________________________________________________________________________ #\n",
    "def exponential_weightedMA(price_series: pd.Series, window: int, ind_lambda: float):\n",
    "    # ======= I. Create the weights using a truncated exponential function =======\n",
    "    weight_range = [(1 - ind_lambda) ** (i - 1) for i in range(1, window + 1)]\n",
    "    weight_range.reverse()\n",
    "    weight_range = np.array(weight_range)\n",
    "\n",
    "    # ======= II. Perform the weighted moving average =======\n",
    "    series = np.array(price_series)\n",
    "    wma = get_weightedMA(series=series, weight_range=weight_range)\n",
    "\n",
    "    # ======= III. Convert to pd.Series =======\n",
    "    wma = pd.Series(wma, index=price_series.index)\n",
    "\n",
    "    return wma\n",
    "\n",
    "#! ==================================================================================== #\n",
    "#! ================================ Helper functions ================================== #\n",
    "def get_weightedMA(series: pd.Series, weight_range: np.array):\n",
    "        # ======= I. Check if the weights are valid =======\n",
    "        values = np.array(series)\n",
    "        values = values.astype(\"float64\")\n",
    "        wma = values.copy()\n",
    "\n",
    "        if isinstance(weight_range, int):\n",
    "            weights = np.array(range(1, weight_range + 1))\n",
    "            rolling_window = weight_range\n",
    "        else:\n",
    "            weights = weight_range\n",
    "            rolling_window = len(weight_range)\n",
    "\n",
    "        # ======= II. Calculate the weighted moving average over a rolling window =======\n",
    "        for i in range(0, len(values)):\n",
    "            try:\n",
    "                wma[i] = values[i - rolling_window + 1 : i + 1].dot(weights) / np.sum(weights)\n",
    "            except:\n",
    "                wma[i] = np.nan\n",
    "\n",
    "        return wma\n",
    "\n",
    "#*____________________________________________________________________________________ #\n",
    "def get_volatility(price_series: pd.Series, window: int):\n",
    "\n",
    "    returns_series = price_series.pct_change().fillna(0)\n",
    "    volatility_series = returns_series.rolling(window).std() * np.sqrt(window)\n",
    "\n",
    "    return volatility_series\n",
    "\n",
    "#! ==================================================================================== #\n",
    "#! ================================ Labelling Process ================================= #\n",
    "def trend_filter(label_series: pd.Series, window: int):\n",
    "    # ======= I. Create an auxiliary DataFrame =======\n",
    "    auxiliary_df = pd.DataFrame()\n",
    "    auxiliary_df[\"label\"] = label_series\n",
    "    \n",
    "    # ======= II. Create a group for each label and extract size =======\n",
    "    auxiliary_df[\"group\"] = (auxiliary_df[\"label\"] != auxiliary_df[\"label\"].shift()).cumsum()\n",
    "    group_sizes = auxiliary_df.groupby(\"group\")[\"label\"].transform(\"size\")\n",
    "\n",
    "    # ======= III. Filter the labels based on the group size =======\n",
    "    auxiliary_df[\"label\"] = auxiliary_df.apply(lambda row: row[\"label\"] if group_sizes[row.name] >= window else 0, axis=1)\n",
    "    labels_series = auxiliary_df[\"label\"]\n",
    "    \n",
    "    return labels_series\n",
    "\n",
    "#*____________________________________________________________________________________ #\n",
    "def tripleBarrier_labeller(price_series: pd.Series, params: dict):\n",
    "    # ======= 0. Params extraction =======\n",
    "    upper_barrier = params[\"upper_barrier\"]\n",
    "    lower_barrier = params[\"lower_barrier\"]\n",
    "    vertical_barrier = params[\"vertical_barrier\"]\n",
    "\n",
    "    # ======= I. Compute volatility target =======\n",
    "    p_series = price_series.dropna().copy()\n",
    "    volatility_series = get_volatility(price_series=p_series, window=vertical_barrier)\n",
    "\n",
    "    # ======= II. Initialize the labeled series and trade side =======\n",
    "    labels_series = pd.Series(index=p_series.index, dtype=int)\n",
    "    trade_side = 0\n",
    "\n",
    "    # ======= III. Iterate through the price series =======\n",
    "    for index in p_series.index:\n",
    "        # III.1 Extract the future prices over the horizon\n",
    "        start_idx = p_series.index.get_loc(index)\n",
    "        end_idx = min(start_idx + vertical_barrier, len(p_series))\n",
    "        future_prices = p_series.iloc[start_idx:end_idx]\n",
    "\n",
    "        # III.2 Compute the range of future returns over the horizon\n",
    "        max_price = future_prices.max()\n",
    "        min_price = future_prices.min()\n",
    "\n",
    "        max_price_index = future_prices.idxmax()\n",
    "        min_price_index = future_prices.idxmin()\n",
    "\n",
    "        max_return = (max_price - p_series.loc[index]) / p_series.loc[index]\n",
    "        min_return = (min_price - p_series.loc[index]) / p_series.loc[index]\n",
    "\n",
    "        # III.3 Adjust the barrier thresholds with the volatility\n",
    "        upper_threshold = upper_barrier * volatility_series.loc[index]\n",
    "        lower_threshold = lower_barrier * volatility_series.loc[index]\n",
    "\n",
    "        # III.4 Check if the horizontal barriers have been hit\n",
    "        long_event = False\n",
    "        short_event = False\n",
    "\n",
    "        if trade_side == 1:  # Long trade\n",
    "            if max_return > upper_threshold:\n",
    "                long_event = True\n",
    "            elif min_return < -lower_threshold:\n",
    "                short_event = True\n",
    "\n",
    "        elif trade_side == -1:  # Short trade\n",
    "            if min_return < -upper_threshold:\n",
    "                short_event = True\n",
    "            elif max_return > lower_threshold:\n",
    "                long_event = True\n",
    "\n",
    "        else:  # No position held\n",
    "            if max_return > upper_threshold:\n",
    "                long_event = True\n",
    "            elif min_return < -upper_threshold:\n",
    "                short_event = True\n",
    "\n",
    "        # III.5 Label based on the first event that occurs\n",
    "        if long_event and short_event:  # If both events occur, choose the first one\n",
    "            if max_price_index < min_price_index:\n",
    "                labels_series.loc[index] = 1\n",
    "            else:\n",
    "                labels_series.loc[index] = -1\n",
    "\n",
    "        elif long_event and not short_event:  # If only long event occurs\n",
    "            labels_series.loc[index] = 1\n",
    "\n",
    "        elif short_event and not long_event:  # If only short event occurs\n",
    "            labels_series.loc[index] = -1\n",
    "\n",
    "        else:  # If no event occurs (vertical hit)\n",
    "            labels_series.loc[index] = 0\n",
    "\n",
    "        # III.6 Update the trade side\n",
    "        trade_side = labels_series.loc[index]\n",
    "\n",
    "    return labels_series\n",
    "\n",
    "#*____________________________________________________________________________________ #\n",
    "def lookForward_labeller(price_series: pd.Series, params: dict):\n",
    "    # ======= 0. Params extraction =======\n",
    "    size_window_smooth = params[\"size_window_smooth\"]\n",
    "    lambda_smooth = params[\"lambda_smooth\"]\n",
    "    trend_size = params[\"trend_size\"]\n",
    "    volatility_threshold = params[\"volatility_threshold\"]\n",
    "\n",
    "    # ======= I. Prepare Series =======\n",
    "    p_series = price_series.dropna().copy()\n",
    "    ewma_series = exponential_weightedMA(price_series=p_series, window=size_window_smooth, ind_lambda=lambda_smooth)\n",
    "\n",
    "    # ======= I. Significant look forward Label =======\n",
    "    # ------- 1. Get the moving X days returns and the moving X days volatility -------\n",
    "    Xdays_returns = (ewma_series.shift(-size_window_smooth) - ewma_series) / ewma_series\n",
    "    Xdays_vol = Xdays_returns.rolling(window=size_window_smooth).std()\n",
    "\n",
    "    # ------- 2. Compare the X days returns to the volatility  -------\n",
    "    Xdays_score = Xdays_returns / Xdays_vol\n",
    "    Xdays_label = Xdays_score.apply(lambda x: 1 if x > volatility_threshold else (-1 if x < -volatility_threshold else 0))\n",
    "\n",
    "    # ------- 3. Eliminate the trends that are too small -------\n",
    "    labels_series = trend_filter(label_series=Xdays_label, window=trend_size)\n",
    "\n",
    "    return labels_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_price_with_labels(price_series, label_series):\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    \n",
    "    # Tracer la série de prix\n",
    "    plt.plot(price_series, label=\"Prix\", color=\"blue\", linewidth=1)\n",
    "    \n",
    "    # Afficher les labels avec des couleurs distinctes\n",
    "    plt.scatter(price_series.index[label_series == 1], \n",
    "                price_series[label_series == 1], \n",
    "                color='green', label=\"Tendance haussière (+1)\", marker=\"^\", s=50)\n",
    "    \n",
    "    plt.scatter(price_series.index[label_series == -1], \n",
    "                price_series[label_series == -1], \n",
    "                color='red', label=\"Tendance baissière (-1)\", marker=\"v\", s=50)\n",
    "    \n",
    "    plt.scatter(price_series.index[label_series == 0], \n",
    "                price_series[label_series == 0], \n",
    "                color='gray', label=\"Neutre (0)\", marker=\"o\", s=10, alpha=0.5)\n",
    "\n",
    "    # Ajouter un titre et une légende\n",
    "    plt.title(\"Prix avec Labels de Tendance\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Prix\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dt.load_data(ticker=\"AAPL\")\n",
    "data = data[\"2019-01-01\":\"2020-01-01\"]\n",
    "price_series = data[\"close\"]\n",
    "\n",
    "labels_series_tb = tripleBarrier_labeller(price_series=price_series, params={\"upper_barrier\": 1, \"lower_barrier\": 1, \"vertical_barrier\": 30})\n",
    "labels_series_lf = lookForward_labeller(price_series=price_series, params={\"size_window_smooth\": 10, \"lambda_smooth\": 0.2, \"trend_size\": 5, \"volatility_threshold\": 1})\n",
    "print('TripleBarrier Labeller :')\n",
    "plot_price_with_labels(price_series, labels_series_tb)\n",
    "print('LookForward Labeller :')\n",
    "plot_price_with_labels(price_series, labels_series_lf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Feature Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_data(feature_series: pd.Series):\n",
    "    # ======= I. Extract Basic Information =======\n",
    "    data_type = feature_series.dtype\n",
    "    \n",
    "    missing_values = feature_series.isnull().sum()\n",
    "    unique_values = feature_series.nunique()\n",
    "    zero_values = (feature_series == 0).sum()\n",
    "    negative_values = (feature_series < 0).sum()\n",
    "    positive_values = (feature_series > 0).sum()\n",
    "    \n",
    "    # ======= II. Visualizing Basic Information =======\n",
    "    print(f\"Data Type: {data_type}\")\n",
    "    print(f\"Missing Values: {missing_values}, Unique Values: {unique_values}\")\n",
    "    print(f\"Zero Values: {zero_values}, Negative Values: {negative_values}, Positive Values: {positive_values}\")\n",
    "    \n",
    "    # ======= III. Store Basic Information =======\n",
    "    basic_info = {\n",
    "        \"Data Type\": data_type,\n",
    "        \"Missing Values\": missing_values,\n",
    "        \"Unique Values\": unique_values,\n",
    "        \"Zero Values\": zero_values,\n",
    "        \"Negative Values\": negative_values,\n",
    "        \"Positive Values\": positive_values\n",
    "    }\n",
    "    \n",
    "    return basic_info\n",
    "\n",
    "#*____________________________________________________________________________________ #\n",
    "def feature_distribution(feature_series: pd.Series, feature_name: str = None):\n",
    "    # ======= O. Feature name =======\n",
    "    if feature_name is None:\n",
    "        feature_name = \"Feature\"\n",
    "    \n",
    "    # ======= I. Extract Descriptive Statistics =======\n",
    "    mean = feature_series.mean()\n",
    "    median = feature_series.median()\n",
    "    min_val = feature_series.min()\n",
    "    max_val = feature_series.max()\n",
    "    std_dev = feature_series.std()\n",
    "    skewness = feature_series.skew()\n",
    "    kurtosis = feature_series.kurtosis()\n",
    "    \n",
    "    # ======= II. Store Descriptive Statistics =======\n",
    "    descriptive_df = pd.DataFrame({\"Mean\": [mean], \"Median\": [median], \"Min\": [min_val], \"Max\": [max_val], \"Std. Dev\": [std_dev], \"Skewness\": [skewness], \"Kurtosis\": [kurtosis]}, index=[feature_name])\n",
    "    \n",
    "    # ======= III. Visualizing Descriptive Statistics =======\n",
    "    plt.figure(figsize=(17, 5))\n",
    "    sns.histplot(feature_series, kde=True, bins=30, color=\"skyblue\", stat=\"density\", linewidth=0, label=f\"{feature_name} Distribution\")\n",
    "\n",
    "    plt.axvline(mean, color='orange', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')\n",
    "    plt.axvline(median, color='green', linestyle='dashed', linewidth=2, label=f'Median: {median:.2f}')\n",
    "    plt.axvline(min_val, color='red', linestyle='dashed', linewidth=2, label=f'Min: {min_val:.2f}')\n",
    "    plt.axvline(max_val, color='blue', linestyle='dashed', linewidth=2, label=f'Max: {max_val:.2f}')\n",
    "    plt.axvspan(mean - std_dev, mean + std_dev, color='yellow', alpha=0.3, label='±1 Std Dev')\n",
    "\n",
    "    plt.title(f'{feature_name} Distribution with Key Statistics')\n",
    "    plt.xlabel(f'{feature_name} Value')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return descriptive_df\n",
    "\n",
    "#*____________________________________________________________________________________ #\n",
    "def feature_plot(feature_series: pd.Series, label_series: pd.Series, feature_name: str = None):\n",
    "    # ======= I. Visualization of the feature against labels =======\n",
    "    plt.figure(figsize=(17, 5))\n",
    "    plt.plot(label_series.index, feature_series, label=feature_name, linewidth=2)\n",
    "\n",
    "    for i, label in label_series.items():\n",
    "        if label == 1:\n",
    "            plt.scatter(i, 0, color='green', label='Reg: Upward Movement', s=10, zorder=5)\n",
    "        elif label == 0:\n",
    "            plt.scatter(i, 0, color='black', label='Reg: Neutral Movement', s=10, zorder=5)\n",
    "        elif label == -1:\n",
    "            plt.scatter(i, 0, color='red', label='Reg: Downward Movement', s=10, zorder=5)\n",
    "\n",
    "    plt.title(f'Feature {feature_name} against Labels')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "    \n",
    "    label_feature_df = pd.DataFrame({'label': label_series, feature_name: feature_series})\n",
    "    plt.figure(figsize=(17, 5))\n",
    "    sns.boxplot(x='label', y=feature_name, data=label_feature_df)\n",
    "    plt.title(f'Boxplot of {feature_name} by Label')\n",
    "    plt.xlabel('Labels')\n",
    "    plt.ylabel(f'{feature_name} Values')\n",
    "    plt.show()\n",
    "\n",
    "def features_correlation(label_feature_df: pd.DataFrame):\n",
    "    # ======= I. Correlation between the feature and the labels =======\n",
    "    light_green = (0, 0.7, 0.3, 0.2)\n",
    "    colors = [(0, 'green'), (0.5, light_green), (0.99, 'green'), (1, 'grey')]\n",
    "    n_bins = 1000\n",
    "    cmap_name = 'green_white'\n",
    "    cm = LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)\n",
    "\n",
    "    corr_matrix = label_feature_df.corr()\n",
    "    plt.figure(figsize=(17, 5))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=cm, vmin=-1, vmax=1, fmt='.2f', linewidths=0.5)\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_features(\n",
    "    price_series: pd.Series,\n",
    "    window: int,\n",
    "):\n",
    "    # ======= I. Compute the different smoothed series =======\n",
    "    rolling_average = price_series.rolling(window=window + 1).apply(lambda x: np.mean(x[:window]))\n",
    "\n",
    "    # ======= II. Convert to pd.Series and Center =======\n",
    "    rolling_average = (pd.Series(rolling_average, index=price_series.index) / (price_series + 1e-8)) - 1\n",
    "    \n",
    "    # ======= III. Change Name =======\n",
    "    rolling_average.name = f\"average_{window}\"\n",
    "\n",
    "    return rolling_average\n",
    "\n",
    "#*____________________________________________________________________________________ #\n",
    "def quantile_features(\n",
    "    price_series: pd.Series,\n",
    "    window: int,\n",
    "    quantile: float,\n",
    "):\n",
    "    # ======= I. Compute the rolling quantile =======\n",
    "    returns_series = price_series.pct_change().dropna()\n",
    "    rolling_quantile = returns_series.rolling(window=window + 1).apply(lambda x: np.quantile(x[:window], quantile))\n",
    "\n",
    "    # ======= II. Convert to pd.Series and Center =======\n",
    "    rolling_quantile = pd.Series(rolling_quantile, index=price_series.index)\n",
    "    \n",
    "    # ======= III. Change Name =======\n",
    "    rolling_quantile.name = f\"quantile_{quantile}_{window}\"\n",
    "\n",
    "    return rolling_quantile\n",
    "\n",
    "average = average_features(price_series, 10)\n",
    "quantile = quantile_features(price_series, 10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_basic_info = feature_data(average)\n",
    "average_descriptive_df = feature_distribution(average, feature_name=average.name)\n",
    "feature_plot(average, labels_series_tb, feature_name=average.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_basic_info = feature_data(quantile)\n",
    "quantile_descriptive_df = feature_distribution(quantile, feature_name=quantile.name)\n",
    "feature_plot(quantile, labels_series_tb, feature_name=quantile.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ==================================================================================== #\n",
    "#! =============================== Auxiliary Functions ================================ #\n",
    "def adapt_learning_rate(learning_rate: float, loss: float, last_loss: float):\n",
    "    new_rate = learning_rate\n",
    "    if loss > last_loss:\n",
    "        new_rate /= 2\n",
    "    else:\n",
    "        new_rate *= 1.05\n",
    "    \n",
    "    return new_rate\n",
    "\n",
    "#*____________________________________________________________________________________ #\n",
    "def early_stopping(loss: float, last_loss: float):\n",
    "    # ======= I. Check the loss diference =======\n",
    "    if last_loss == np.inf:\n",
    "        return False\n",
    "    \n",
    "    loss_diff = np.abs(loss - last_loss)\n",
    "    early_stop = False\n",
    "    \n",
    "    # ======= II. Check if the loss difference is small enough =======\n",
    "    if loss_diff < 1e-5:\n",
    "        early_stop = True\n",
    "    \n",
    "    return early_stop\n",
    "\n",
    "\n",
    "\n",
    "#! ==================================================================================== #\n",
    "#! =================================== Base Models ==================================== #\n",
    "class LinearRegression(ABC):\n",
    "\n",
    "    def __init__(self):\n",
    "        # --- Data Fitted ---\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "        self.X_test = None\n",
    "        self.predictions = None\n",
    "        \n",
    "        # --- Model Parameters ---\n",
    "        self.coefficients = None\n",
    "        self.intercept = None\n",
    "        \n",
    "        # --- Model Statistics ---\n",
    "        self.statistics = None\n",
    "        self.residuals = None\n",
    "        self.loss_history = None\n",
    "        \n",
    "    # ------------------------------- Auxiliary Functions -------------------------------- #\n",
    "    def process_data(self, X_train, y_train):\n",
    "        # ======= I. Convert X and y to numpy arrays =======\n",
    "        X = np.array(X_train).reshape(-1, 1) if len(np.array(X_train).shape) == 1 else np.array(X_train)\n",
    "        y = np.array(y_train)\n",
    "        \n",
    "        # ======= II. Store training data =======\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    # ____________________________________________________________________________________ #\n",
    "    @abstractmethod\n",
    "    def gradient_descent(self, learning_rate: float, epochs: int, features_matrix: np.array, target_vector: np.array):\n",
    "        pass\n",
    "\n",
    "    # -------------------------------- Callable Functions -------------------------------- #\n",
    "    def fit(self, X_train, y_train, learning_rate=0.001, epochs=1000):\n",
    "        # ======= I. Process Data =======\n",
    "        X, y = self.process_data(X_train, y_train)\n",
    "        \n",
    "        # ======= II. Perform Gradient Descent to extract the coefficients =======\n",
    "        coefficients, intercept = self.gradient_descent(learning_rate, epochs, X, y)\n",
    "        self.coefficients = coefficients\n",
    "        self.intercept = intercept\n",
    "        \n",
    "    # ____________________________________________________________________________________ #\n",
    "    def predict(self, X_test):\n",
    "        # ======= I. Convert X to a numpy array =======\n",
    "        X = np.array(X_test).reshape(-1, 1) if len(np.array(X_test).shape) == 1 else np.array(X_test)\n",
    "        \n",
    "        # ======= II. Make predictions =======\n",
    "        predictions = self.intercept + np.dot(X, self.coefficients)\n",
    "        self.predictions = predictions\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    # --------------------------------- Model Statistics --------------------------------- #\n",
    "    def get_statistics(self):\n",
    "        # ======= I. Extract the residuals =======\n",
    "        predictions = self.predict(self.X_train)\n",
    "        residuals = self.y_train - predictions\n",
    "        \n",
    "        # ======= II. Compute the residuals descriptive statistics =======\n",
    "        nb_observations, nb_features = self.X_train.shape\n",
    "        \n",
    "        variance = np.sum(residuals**2) / (nb_observations - nb_features)\n",
    "        mean = np.mean(residuals)\n",
    "        median = np.median(residuals)\n",
    "\n",
    "        # ======= III. Compute the R-squared =======\n",
    "        SST = np.sum((self.y_train - np.mean(self.y_train))**2)\n",
    "        SSR = np.sum((predictions - np.mean(self.y_train))**2)\n",
    "        R_squared = SSR / SST\n",
    "        \n",
    "        # ======= IV. Compute the t-stats and p-values =======\n",
    "        var_covar_matrix = variance * np.linalg.inv(self.X_train.T @ self.X_train)\n",
    "        se_coefficients = np.sqrt(np.diag(var_covar_matrix))\n",
    "        t_stats = self.coefficients / se_coefficients\n",
    "        \n",
    "        degrees_freedom = nb_observations - nb_features\n",
    "        p_values = [2 * (1 - t.cdf(np.abs(t_stat), degrees_freedom)) for t_stat in t_stats]\n",
    "        \n",
    "        # ======= V. Store the statistics =======\n",
    "        statistics = {\n",
    "            \"Variance\": variance,\n",
    "            \"Mean\": mean,\n",
    "            \"Median\": median,\n",
    "            \"R_squared\": R_squared,\n",
    "            \"T_stats\": t_stats,\n",
    "            \"P_values\": p_values\n",
    "        }\n",
    "        \n",
    "        self.statistics = statistics\n",
    "        self.residuals = residuals\n",
    "\n",
    "        return statistics, residuals\n",
    "    \n",
    "    # -------------------------------- Model Visualization ------------------------------- #\n",
    "    def plot_loss_history(self):\n",
    "        \n",
    "        plt.figure(figsize=(17, 5))\n",
    "        plt.plot(self.loss_history, color=\"blue\", linewidth=2)\n",
    "        plt.title(\"Loss History\", fontsize=16)\n",
    "        plt.xlabel(\"Epochs\", fontsize=14)\n",
    "        plt.ylabel(\"Loss\", fontsize=14)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        return None\n",
    "\n",
    "    # ____________________________________________________________________________________ #\n",
    "    def plot_fitted_line(self, feature_index=0):\n",
    "        # ======= I. Extract the feature values =======\n",
    "        X = self.X_train[:, feature_index]\n",
    "        X = np.array(X).reshape(-1, 1)\n",
    "        \n",
    "        # ======= II. Compute the feature range =======\n",
    "        min_feature = X.min()\n",
    "        max_feature = X.max()\n",
    "        feature_range = max_feature - min_feature\n",
    "        rate = 0.001 * feature_range\n",
    "\n",
    "        # ======= III. Create a range of feature values for plotting =======\n",
    "        plotting_range = np.arange(min_feature - rate, max_feature + rate, rate)\n",
    "\n",
    "        # ======= IV. Compute the fitted line =======\n",
    "        fitted_line = self.intercept + plotting_range * self.coefficients[feature_index]\n",
    "\n",
    "        # ======= V. Plot the fitted line =======\n",
    "        plt.figure(figsize=(17, 5))\n",
    "        plt.scatter(X, self.y_train, color=\"blue\", label=\"Data Points\")\n",
    "        plt.plot(plotting_range, fitted_line, color=\"red\", linewidth=2, label=\"Fitted Line\")\n",
    "        plt.title(\"Fitted Line\", fontsize=16)\n",
    "        plt.xlabel(\"Feature\", fontsize=14)\n",
    "        plt.ylabel(\"Target\", fontsize=14)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        return None\n",
    "\n",
    "    # ____________________________________________________________________________________ #\n",
    "    def plot_residuals(self):\n",
    "        # ======= I. Extract the residuals =======\n",
    "        predictions = self.predict(self.X_train)\n",
    "        residuals = self.y_train - predictions\n",
    "        \n",
    "        # ======= II. Compute the residuals descriptive statistics =======\n",
    "        nb_observations, nb_features = self.X_train.shape\n",
    "        \n",
    "        variance = np.sum(residuals**2) / (nb_observations - nb_features)\n",
    "        mean = np.mean(residuals)\n",
    "        median = np.median(residuals)\n",
    "        \n",
    "        # ======= III. Plot the residuals =======\n",
    "        plt.figure(figsize=(17, 5))\n",
    "        plt.scatter(predictions, residuals, color=\"black\")\n",
    "        plt.axhline(y=mean, color=\"blue\", linestyle=\"--\")\n",
    "        plt.axhline(y=median, color=\"pink\", linestyle=\"--\")\n",
    "        plt.axhline(y=mean + np.sqrt(variance), color=\"green\", linestyle=\"--\")\n",
    "        plt.axhline(y=mean - np.sqrt(variance), color=\"green\", linestyle=\"--\")\n",
    "        plt.axhline(y=mean + 2 * np.sqrt(variance), color=\"red\", linestyle=\"--\")\n",
    "        plt.axhline(y=mean - 2 * np.sqrt(variance), color=\"red\", linestyle=\"--\")\n",
    "        plt.title(\"Residuals\", fontsize=16)\n",
    "        plt.xlabel(\"Predictions\", fontsize=14)\n",
    "        plt.ylabel(\"Residuals\", fontsize=14)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        return residuals\n",
    "        \n",
    "\n",
    "\n",
    "#! ==================================================================================== #\n",
    "#! ================================ Regression Models ================================= #\n",
    "class OLSRegression(LinearRegression):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def gradient_descent(self, learning_rate, epochs, features_matrix, target_vector):\n",
    "         # Add a column of ones to X to account for the intercept\n",
    "        X_with_intercept = np.c_[np.ones((features_matrix.shape[0], 1)), features_matrix]\n",
    "\n",
    "        # Calculate the coefficients using the normal equation\n",
    "        coefficients = np.linalg.inv(X_with_intercept.T @ X_with_intercept) @ X_with_intercept.T @ target_vector\n",
    "\n",
    "        # Extract the intercept and coefficients\n",
    "        intercept = coefficients[0]\n",
    "        coefficients = coefficients[1:]\n",
    "\n",
    "        return coefficients, intercept\n",
    "\n",
    "#*____________________________________________________________________________________ #\n",
    "class MSERegression(LinearRegression):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    # ____________________________________________________________________________________ #\n",
    "    def MSE_gradient(self, nb_observations: int, errors: np.array, features_matrix: np.array):\n",
    "        \n",
    "        gradient_coefficients = (-2 / nb_observations) * np.dot(features_matrix.T, errors)\n",
    "        gradient_intercept = (-2 / nb_observations) * np.sum(errors)\n",
    "        \n",
    "        return gradient_coefficients, gradient_intercept\n",
    "\n",
    "    # ____________________________________________________________________________________ #\n",
    "    def gradient_descent(self, learning_rate: float, epochs: int, features_matrix: np.array, target_vector: np.array):\n",
    "        # ======= I. Initialize coefficients and intercept to 0 =======\n",
    "        learningRate = learning_rate\n",
    "        nb_observations, nb_features = features_matrix.shape\n",
    "        \n",
    "        coefficients = np.zeros(nb_features)\n",
    "        intercept = 0\n",
    "\n",
    "        # ======= II. Perform gradient descent =======\n",
    "        last_loss = np.inf\n",
    "        loss_history = []\n",
    "        for _ in range(epochs):\n",
    "            # II.1 Make a prediction with the current coefficients and intercept\n",
    "            predictions = intercept + np.dot(features_matrix, coefficients)\n",
    "\n",
    "            # II.2 Compute the current errors\n",
    "            errors = predictions - target_vector\n",
    "            loss = np.sum(errors ** 2) / nb_observations\n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            # II.3 Update Learning Rate based on the loss\n",
    "            learningRate = adapt_learning_rate(learningRate, loss, last_loss)\n",
    "            early_stop = early_stopping(loss, last_loss)\n",
    "            if early_stop:\n",
    "                break\n",
    "            last_loss = loss\n",
    "            \n",
    "            # II.4 Compute the gradient of the loss function\n",
    "            gradient_coefficients, gradient_intercept = self.MSE_gradient(nb_observations, errors, features_matrix)\n",
    "\n",
    "            # II.5 Update coefficients and intercept\n",
    "            coefficients += learningRate * gradient_coefficients\n",
    "            intercept += learningRate * gradient_intercept\n",
    "        \n",
    "        self.loss_history = loss_history\n",
    "\n",
    "        return coefficients, intercept\n",
    "\n",
    "#*____________________________________________________________________________________ #\n",
    "class RidgeRegression(LinearRegression):\n",
    "    \n",
    "    def __init__(self, lambda_: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    # ____________________________________________________________________________________ #\n",
    "    def ridge_gradient(self, nb_observations: int, errors: np.array, features_matrix: np.array, lambda_: float, coefficients: np.array):\n",
    "        \n",
    "        gradient_coefficients = (-2 / nb_observations) * np.dot(features_matrix.T, errors) + 2 * lambda_ * coefficients\n",
    "        gradient_intercept = (-2 / nb_observations) * np.sum(errors)\n",
    "\n",
    "        return gradient_coefficients, gradient_intercept\n",
    "\n",
    "    # ____________________________________________________________________________________ #\n",
    "    def gradient_descent(self, learning_rate: float, epochs: int, features_matrix: np.array, target_vector: np.array):\n",
    "        # ======= I. Initialize coefficients and intercept to 0 =======\n",
    "        learningRate = learning_rate\n",
    "        nb_observations, nb_features = features_matrix.shape\n",
    "        lambda_ = self.lambda_\n",
    "        \n",
    "        coefficients = np.zeros(nb_features)\n",
    "        intercept = 0\n",
    "\n",
    "        # ======= II. Perform gradient descent =======\n",
    "        last_loss = np.inf\n",
    "        loss_history = []\n",
    "        for _ in range(epochs):\n",
    "            # II.1 Make a prediction with the current coefficients and intercept\n",
    "            predictions = intercept + np.dot(features_matrix, coefficients)\n",
    "\n",
    "            # II.2 Compute the current errors\n",
    "            errors = predictions - target_vector\n",
    "            loss = np.sum(errors ** 2) / nb_observations\n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            # II.3 Update Learning Rate based on the loss\n",
    "            learningRate = adapt_learning_rate(learningRate, loss, last_loss)\n",
    "            early_stop = early_stopping(loss, last_loss)\n",
    "            if early_stop:\n",
    "                break\n",
    "            last_loss = loss\n",
    "            \n",
    "            # II.4 Compute the gradient of the loss function\n",
    "            gradient_coefficients, gradient_intercept = self.ridge_gradient(nb_observations, errors, features_matrix, lambda_, coefficients)\n",
    "\n",
    "            # II.5 Update coefficients and intercept\n",
    "            coefficients += learningRate * gradient_coefficients\n",
    "            intercept += learningRate * gradient_intercept\n",
    "        \n",
    "        self.loss_history = loss_history\n",
    "\n",
    "        return coefficients, intercept\n",
    "\n",
    "#*____________________________________________________________________________________ #\n",
    "class LassoRegression(LinearRegression):\n",
    "        \n",
    "    def __init__(self, lambda_: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    # ____________________________________________________________________________________ #\n",
    "    def lasso_gradient(self, nb_observations: int, errors: np.array, features_matrix: np.array, lambda_: float, coefficients: np.array):\n",
    "        \n",
    "        gradient_coefficients = (-2 / nb_observations) * np.dot(features_matrix.T, errors) + lambda_ * np.sign(coefficients)\n",
    "        gradient_intercept = (-2 / nb_observations) * np.sum(errors)\n",
    "\n",
    "        return gradient_coefficients, gradient_intercept\n",
    "\n",
    "    # ____________________________________________________________________________________ #\n",
    "    def gradient_descent(self, learning_rate: float, epochs: int, features_matrix: np.array, target_vector: np.array):\n",
    "        # ======= I. Initialize coefficients and intercept to 0 =======\n",
    "        learningRate = learning_rate\n",
    "        nb_observations, nb_features = features_matrix.shape\n",
    "        lambda_ = self.lambda_\n",
    "        \n",
    "        coefficients = np.zeros(nb_features)\n",
    "        intercept = 0\n",
    "\n",
    "        # ======= II. Perform gradient descent =======\n",
    "        last_loss = np.inf\n",
    "        loss_history = []\n",
    "        for _ in range(epochs):\n",
    "            # II.1 Make a prediction with the current coefficients and intercept\n",
    "            predictions = intercept + np.dot(features_matrix, coefficients)\n",
    "\n",
    "            # II.2 Compute the current errors\n",
    "            errors = predictions - target_vector\n",
    "            loss = np.sum(errors ** 2) / nb_observations\n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            # II.3 Update Learning Rate based on the loss\n",
    "            learningRate = adapt_learning_rate(learningRate, loss, last_loss)\n",
    "            early_stop = early_stopping(loss, last_loss)\n",
    "            if early_stop:\n",
    "                break\n",
    "            last_loss = loss\n",
    "            \n",
    "            # II.4 Compute the gradient of the loss function\n",
    "            gradient_coefficients, gradient_intercept = self.lasso_gradient(nb_observations, errors, features_matrix, lambda_, coefficients)\n",
    "\n",
    "            # II.5 Update coefficients and intercept\n",
    "            coefficients += learningRate * gradient_coefficients\n",
    "            intercept += learningRate * gradient_intercept\n",
    "        \n",
    "        self.loss_history = loss_history\n",
    "\n",
    "        return coefficients, intercept\n",
    "\n",
    "#*____________________________________________________________________________________ #\n",
    "class ElasticNetRegression(LinearRegression):\n",
    "        \n",
    "    def __init__(self, lambda1: float = 0.1, lambda2: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "\n",
    "    # ____________________________________________________________________________________ #\n",
    "    def elastic_net_gradient(self, nb_observations: int, errors: np.array, features_matrix: np.array, lambda1: float, lambda2: float, coefficients: np.array):\n",
    "        \n",
    "        gradient_coefficients = (-2 / nb_observations) * np.dot(features_matrix.T, errors) + 2 * lambda1 * coefficients + lambda2 * np.sign(coefficients)\n",
    "        gradient_intercept = (-2 / nb_observations) * np.sum(errors)\n",
    "\n",
    "        return gradient_coefficients, gradient_intercept\n",
    "\n",
    "    # ____________________________________________________________________________________ #\n",
    "    def gradient_descent(self, learning_rate: float, epochs: int, features_matrix: np.array, target_vector: np.array, lambda1: float = 1, lambda2: float = 1):\n",
    "        # ======= I. Initialize coefficients and intercept to 0 =======\n",
    "        learningRate = learning_rate\n",
    "        nb_observations, nb_features = features_matrix.shape\n",
    "        lambda1 = self.lambda1\n",
    "        lambda2 = self.lambda2\n",
    "        \n",
    "        coefficients = np.zeros(nb_features)\n",
    "        intercept = 0\n",
    "\n",
    "        # ======= II. Perform gradient descent =======\n",
    "        last_loss = np.inf\n",
    "        loss_history = []\n",
    "        for _ in range(epochs):\n",
    "            # II.1 Make a prediction with the current coefficients and intercept\n",
    "            predictions = intercept + np.dot(features_matrix, coefficients)\n",
    "\n",
    "            # II.2 Compute the current errors\n",
    "            errors = predictions - target_vector\n",
    "            loss = np.sum(errors ** 2) / nb_observations\n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            # II.3 Update Learning Rate based on the loss\n",
    "            learningRate = adapt_learning_rate(learningRate, loss, last_loss)\n",
    "            early_stop = early_stopping(loss, last_loss)\n",
    "            if early_stop:\n",
    "                break\n",
    "            last_loss = loss\n",
    "            \n",
    "            # II.4 Compute the gradient of the loss function\n",
    "            gradient_coefficients, gradient_intercept = self.elastic_net_gradient(nb_observations, errors, features_matrix, lambda1, lambda2, coefficients)\n",
    "\n",
    "            # II.5 Update coefficients and intercept\n",
    "            coefficients += learningRate * gradient_coefficients\n",
    "            intercept += learningRate * gradient_intercept\n",
    "        \n",
    "        self.loss_history = loss_history\n",
    "\n",
    "        return coefficients, intercept\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_TempReg(series: pd.Series):\n",
    "    # ======= I. Fit the temporal regression =======\n",
    "    X = np.arange(len(series))\n",
    "    model = OLSRegression()\n",
    "    model.fit(X, series)\n",
    "    \n",
    "    # ======= II. Extract the coefficients and statistics =======\n",
    "    coefficients = model.coefficients\n",
    "    intercept = model.intercept\n",
    "    \n",
    "    statistics, residuals = model.get_statistics()\n",
    "\n",
    "    return intercept, coefficients, statistics,residuals\n",
    "\n",
    "#*____________________________________________________________________________________ #\n",
    "def linear_tempReg_features(\n",
    "    price_series: pd.Series, \n",
    "    regression_window: int\n",
    "):\n",
    "    # ======= 0. Intermediate functions =======\n",
    "    def compute_slope(series):\n",
    "        _, coefficients, _, _ = get_simple_TempReg(series)\n",
    "        slope = coefficients[0]\n",
    "        \n",
    "        return slope\n",
    "\n",
    "    def compute_T_stats(series):\n",
    "        _, _, statistics, _ = get_simple_TempReg(series)\n",
    "        T_stats = statistics['T_stats'][0]\n",
    "        \n",
    "        return T_stats\n",
    "    \n",
    "    def compute_Pvalue(series):\n",
    "        _, _, statistics, _ = get_simple_TempReg(series)\n",
    "        P_value = statistics['P_values'][0]\n",
    "        \n",
    "        return P_value\n",
    "    \n",
    "    def compute_R_squared(series):\n",
    "        _, _, statistics, _ = get_simple_TempReg(series)\n",
    "        R_squared = statistics['R_squared']\n",
    "        \n",
    "        return R_squared\n",
    "\n",
    "    # ======= I. Verify the price series is large enough =======\n",
    "    if len(price_series) < regression_window:\n",
    "        raise ValueError(\"Price series length must be greater than or equal to the regression window.\")\n",
    "\n",
    "    # ======= II. Compute the rolling regression statistics =======\n",
    "    rolling_slope = price_series.rolling(window=regression_window + 1).apply(compute_slope, raw=False)\n",
    "    rolling_tstat = price_series.rolling(window=regression_window + 1).apply(compute_T_stats, raw=False)\n",
    "    rolling_pvalue = price_series.rolling(window=regression_window + 1).apply(compute_Pvalue, raw=False)\n",
    "    rolling_r_squared = price_series.rolling(window=regression_window + 1).apply(compute_R_squared, raw=False)\n",
    "\n",
    "    # ======= III. Convert to pd.Series and Unscale =======\n",
    "    rolling_slope = pd.Series(rolling_slope, index=price_series.index) / (price_series + 1e-8)\n",
    "    rolling_tstat = pd.Series(rolling_tstat, index=price_series.index)\n",
    "    rolling_pvalue = pd.Series(rolling_pvalue, index=price_series.index)\n",
    "    rolling_r_squared = pd.Series(rolling_r_squared, index=price_series.index)\n",
    "    \n",
    "    # ======= IV. Change Name =======\n",
    "    rolling_slope.name = f\"linear_slope_{regression_window}\"\n",
    "    rolling_tstat.name = f\"linear_tstat_{regression_window}\"\n",
    "    rolling_pvalue.name = f\"linear_pvalue_{regression_window}\"\n",
    "    rolling_r_squared.name = f\"linear_r_squared_{regression_window}\"\n",
    "\n",
    "    return rolling_slope, rolling_tstat, rolling_pvalue, rolling_r_squared\n",
    "\n",
    "#*____________________________________________________________________________________ #\n",
    "def hurst_exponent_features(\n",
    "    price_series: pd.Series, \n",
    "    power: int\n",
    "):\n",
    "    # ======= I. Initialize the variables =======\n",
    "    prices_array = np.array(price_series)\n",
    "    returns_array = prices_array[1:] / prices_array[:-1] - 1\n",
    "\n",
    "    n = 2**power\n",
    "\n",
    "    hursts = np.array([])\n",
    "    tstats = np.array([])\n",
    "    pvalues = np.array([])\n",
    "\n",
    "    # ======= II. Compute the Hurst Exponent =======\n",
    "    for t in np.arange(n, len(returns_array) + 1):\n",
    "        data = returns_array[t - n : t]\n",
    "        X = np.arange(2, power + 1)\n",
    "        Y = np.array([])\n",
    "\n",
    "        for p in X:\n",
    "            m = 2**p\n",
    "            s = 2 ** (power - p)\n",
    "            rs_array = np.array([])\n",
    "\n",
    "            for i in np.arange(0, s):\n",
    "                subsample = data[i * m : (i + 1) * m]\n",
    "                mean = np.average(subsample)\n",
    "                deviate = np.cumsum(subsample - mean)\n",
    "                difference = max(deviate) - min(deviate)\n",
    "                stdev = np.std(subsample)\n",
    "                rescaled_range = difference / stdev\n",
    "                rs_array = np.append(rs_array, rescaled_range)\n",
    "\n",
    "            Y = np.append(Y, np.log2(np.average(rs_array)))\n",
    "\n",
    "        model = OLSRegression()\n",
    "        model.fit(X, Y)\n",
    "        \n",
    "        hurst = model.coefficients[0]\n",
    "        statistics, _ = model.get_statistics()\n",
    "        tstat = statistics['T_stats'][0]\n",
    "        pvalue = statistics['P_values'][0]\n",
    "        \n",
    "        hursts = np.append(hursts, hurst)\n",
    "        tstats = np.append(tstats, tstat)\n",
    "        pvalues = np.append(pvalues, pvalue)\n",
    "\n",
    "    # ======= III. Convert to pd.Series and Center =======\n",
    "    hursts = pd.Series([np.nan] * n + list(hursts), index=price_series.index) - 0.5\n",
    "    tstats = pd.Series([np.nan] * n + list(tstats), index=price_series.index)\n",
    "    pvalues = pd.Series([np.nan] * n + list(pvalues), index=price_series.index)\n",
    "\n",
    "    tstats_mean = tstats.rolling(window=252).mean()\n",
    "    tstats = tstats - tstats_mean\n",
    "\n",
    "    pvalues_mean = pvalues.rolling(window=252).mean()\n",
    "    pvalues = pvalues - pvalues_mean\n",
    "    \n",
    "    # ======= IV. Change Name =======\n",
    "    hursts.name = f\"hurst_exponent{power}\"\n",
    "    tstats.name = f\"hurst_tstat_{power}\"\n",
    "    pvalues.name = f\"hurst_pvalue_{power}\"\n",
    "\n",
    "    return hursts, tstats, pvalues\n",
    "\n",
    "rolling_slope, rolling_tstat, rolling_pvalue, rolling_r_squared = linear_tempReg_features(price_series, 10)\n",
    "hursts, tstats, pvalues = hurst_exponent_features(price_series, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_basic_info = feature_data(rolling_slope)\n",
    "slope_descriptive_df = feature_distribution(rolling_slope, feature_name=rolling_slope.name)\n",
    "feature_plot(rolling_slope, labels_series_tb, feature_name=rolling_slope.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hurst_basic_info = feature_data(hursts)\n",
    "hurst_descriptive_df = feature_distribution(hursts, feature_name=hursts.name)\n",
    "feature_plot(hursts, labels_series_tb, feature_name=hursts.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1700x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_df = pd.DataFrame({\n",
    "    'label': labels_series_lf,\n",
    "    \"average\": average,\n",
    "    \"quantile\": quantile,\n",
    "    \"rolling_slope\": rolling_slope,\n",
    "    \"hurst\": hursts,\n",
    "})\n",
    "\n",
    "features_correlation(features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy(ABC):\n",
    "    def __init__(self):\n",
    "        # ======= Adapt columns name to the available data / operational consideration =======\n",
    "        self.date_name = \"date\"\n",
    "        self.bid_open_name = \"open\"\n",
    "        self.ask_open_name = \"open\"\n",
    "        \n",
    "        # ======= Store Data used for the strategy =======\n",
    "        self.data = None\n",
    "        self.processed_data = None\n",
    "    \n",
    "    #*____________________________________________________________________________________ #\n",
    "    def set_names(self, date_name: str, bid_open_name: str, ask_open_name: str):\n",
    "        \"\"\"\n",
    "        Set the names of the columns used in the data, it is important to ensure the operations are done using the correct price. \n",
    "        For daily data, it is common to use the open or close price for both bid and ask. The bid-ask spread is usually estimated as a slippage cost.\n",
    "        \n",
    "            - date_name (str) : name of the column containing the dates\n",
    "            - bid_open_name (str) : name of the column containing the bid open prices at which the strategy will operate\n",
    "            - ask_open_name (str) : name of the column containing the ask open prices at which the strategy will operate\n",
    "        \"\"\"\n",
    "        self.date_name = date_name\n",
    "        self.bid_open_name = bid_open_name\n",
    "        self.ask_open_name = ask_open_name\n",
    "    \n",
    "    #*____________________________________________________________________________________ #\n",
    "    @abstractmethod\n",
    "    def set_params(self):\n",
    "        \"\"\"This method should be used to set the different parameters of the model.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    #*____________________________________________________________________________________ #\n",
    "    @abstractmethod\n",
    "    def load_data(self):\n",
    "        \"\"\"This method should be used to load the data.\"\"\"\n",
    "        pass\n",
    "\n",
    "    #*____________________________________________________________________________________ #\n",
    "    @abstractmethod\n",
    "    def process_data(self):\n",
    "        \"\"\"\n",
    "        This method should be used to process the data : normalization, feature engineering, etc.\n",
    "        It is expected to output a list of pd.DataFrame containing the processed data, each element of the list will then be used independtly to predict the signals.\n",
    "        For daily data, returning a list containing a unique element is enough. Different elements can be used to avoid overnight bias when operating only intraday.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    #*____________________________________________________________________________________ #\n",
    "    @abstractmethod\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        This method should be used to train the model, optimize hyperparameters and so on.\n",
    "        It does not explicitly split samples, this has to be done by the user before calling this method.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    #*____________________________________________________________________________________ #\n",
    "    @abstractmethod\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        This method should be used to predict the signals.\n",
    "        It is expected to return a pd.DataFrame containing the necessary data to compute the operations (signals, price, date, etc.).\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    #*____________________________________________________________________________________ #\n",
    "    def operate(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        This method is common to all strategies and is used to extract the operations from the signals.\n",
    "        The outputs are the operations (each line corresponds to a different trade) and the signals (each line corresponds to a bar with the associated signal) DataFrames.\n",
    "        \n",
    "            - df (pd.DataFrame) : DataFrame containing the data used to extract the operations\n",
    "        \"\"\"\n",
    "        # ======= I. Extract signals =======\n",
    "        signals_df = self.predict(df=df)\n",
    "        \n",
    "        # ======= II. Objects initialization before extracting operations =======\n",
    "        operations_df = pd.DataFrame(columns=['ID', 'Side', 'Entry_Date', 'Entry_Price', 'Exit_Date', 'Exit_Price', 'PnL'])\n",
    "        \n",
    "        # II.1 Set first and last signal to 0 to ensure that the operations are closed\n",
    "        signals_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        signals_df.loc[0, \"signal\"] = 0\n",
    "        signals_df.loc[len(signals_df) - 1, \"signal\"] = 0\n",
    "        signals_df.loc[len(signals_df) - 2, \"signal\"] = 0\n",
    "\n",
    "        # II.2 Extract the Signal Change and the Entry Points\n",
    "        signals_df[\"Signal Change\"] = signals_df[\"signal\"].diff()\n",
    "        signals_df[\"Signal Change\"] = signals_df[\"Signal Change\"].shift(1) #! Shifted to avoid look-ahead bias\n",
    "\n",
    "        entry_points = signals_df[signals_df[\"Signal Change\"] != 0].copy()\n",
    "        nb_entry = len(entry_points)\n",
    "        \n",
    "        # ======= III. Create an Operation for each entry point =======\n",
    "        sequential_id = 0\n",
    "        for idx in range(nb_entry - 1):\n",
    "            # III.1 Extracting rows\n",
    "            current_row = entry_points.iloc[idx]\n",
    "            next_row = entry_points.iloc[idx + 1]\n",
    "            previous_row = signals_df.iloc[current_row.name - 1]\n",
    "\n",
    "            # III.2 Extract Information for a Long Operation\n",
    "            if (current_row[\"Signal Change\"] > 0 and previous_row[\"signal\"] == 1):\n",
    "                side = 1\n",
    "                entry_date = current_row[self.date_name]\n",
    "                entry_price = current_row[self.ask_open_name]\n",
    "                exit_date = next_row[self.date_name]\n",
    "                exit_price = next_row[self.bid_open_name]\n",
    "                pnl = (exit_price - entry_price)\n",
    "\n",
    "            # III.3 Extract Information for a Short Operation\n",
    "            elif (current_row[\"Signal Change\"] < 0 and previous_row[\"signal\"] == -1):\n",
    "                side = -1\n",
    "                entry_date = current_row[self.date_name]\n",
    "                entry_price = current_row[self.bid_open_name]\n",
    "                exit_date = next_row[self.date_name]\n",
    "                exit_price = next_row[self.ask_open_name]\n",
    "                pnl = (entry_price - exit_price)\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # III.4 Append Operation to the DataFrame\n",
    "            operations_df.loc[sequential_id] = [\n",
    "                sequential_id,\n",
    "                side,\n",
    "                entry_date,\n",
    "                entry_price,\n",
    "                exit_date,\n",
    "                exit_price,\n",
    "                pnl,\n",
    "            ]\n",
    "\n",
    "            # --- New sequential id for the next loop iteration ---\n",
    "            sequential_id += 1\n",
    "        \n",
    "        return operations_df, signals_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We first define some functions to compute the performance metrics of a given strategy.\n",
    "\"\"\"\n",
    "\n",
    "def get_distribution(returns_series: pd.Series, frequence: str = \"daily\"):\n",
    "    \"\"\"\n",
    "    - Expected Return: The annualized mean return, indicating average performance.\n",
    "    - Volatility: Standard deviation of returns, representing total risk.\n",
    "    - Downside Deviation: Standard deviation of negative returns, used in risk-adjusted metrics like Sortino Ratio.\n",
    "    - Median Return: The median of returns, a measure of central tendency.\n",
    "    - Skew & Kurtosis: Describe the distribution shape, with skew indicating asymmetry and kurtosis indicating tail heaviness.\n",
    "    \"\"\"\n",
    "    # ======= I. Get the right frequence =======\n",
    "    frequence_dict = {\"daily\": 252, \"5m\": 19656, \"1m\": 98280}\n",
    "    adjusted_frequence = frequence_dict[frequence]\n",
    "    \n",
    "    # ======= II. Compute the statistics =======\n",
    "    expected_return = returns_series.mean() * adjusted_frequence\n",
    "    volatility = returns_series.std() * np.sqrt(adjusted_frequence)\n",
    "    downside_deviation = returns_series[returns_series < 0].std() * np.sqrt(adjusted_frequence) if returns_series[returns_series < 0].sum() != 0 else 0\n",
    "    median_return = returns_series.median() * adjusted_frequence\n",
    "    skew = returns_series.skew()\n",
    "    kurtosis = returns_series.kurtosis()\n",
    "    \n",
    "    # ======= III. Store the statistics =======\n",
    "    distribution_stats = {\n",
    "        \"expected_return\": expected_return,\n",
    "        \"volatility\": volatility,\n",
    "        \"downside_deviation\": downside_deviation,\n",
    "        \"median_return\": median_return,\n",
    "        \"skew\": skew,\n",
    "        \"kurtosis\": kurtosis,\n",
    "    }\n",
    "    \n",
    "    return distribution_stats\n",
    "\n",
    "# ____________________________________________________________________________________ #\n",
    "def get_risk_measures(returns_series: pd.Series):\n",
    "    \"\"\"\n",
    "    - Maximum Drawdown: Largest observed loss from peak to trough, a measure of downside risk.\n",
    "    - Max Drawdown Duration: Longest period to recover from drawdown, indicating risk recovery time.\n",
    "    - VaR 95 and CVaR 95: Value at Risk and Conditional Value at Risk at 95%, giving the maximum and average expected losses in worst-case scenarios.\n",
    "    \"\"\"\n",
    "    # ======= I. Compute the Cumulative returns =======    \n",
    "    cumulative_returns = (1 + returns_series).cumprod()\n",
    "    \n",
    "    # ======= II. Compute the statistics =======\n",
    "    # ------ Maximum Drawdown and Duration\n",
    "    running_max = cumulative_returns.cummax().replace(0, 1e-10)\n",
    "    drawdown = (cumulative_returns / running_max) - 1\n",
    "    drawdown_durations = (drawdown < 0).astype(int).groupby((drawdown == 0).cumsum()).cumsum()\n",
    "\n",
    "    maximum_drawdown = drawdown.min()\n",
    "    max_drawdown_duration = drawdown_durations.max()\n",
    "\n",
    "    # ------ Value at Risk and Conditional Value at Risk\n",
    "    var_95 = returns_series.quantile(0.05)\n",
    "    cvar_95 = returns_series[returns_series <= var_95].mean()\n",
    "    \n",
    "    # ======= III. Store the statistics =======\n",
    "    risk_stats = {\n",
    "        \"drawdown\": drawdown,\n",
    "        \"maximum_drawdown\": maximum_drawdown,\n",
    "        \"max_drawdown_duration\": max_drawdown_duration,\n",
    "        \"var_95\": var_95,\n",
    "        \"cvar_95\": cvar_95,\n",
    "    }\n",
    "    \n",
    "    return risk_stats\n",
    "\n",
    "# ____________________________________________________________________________________ #\n",
    "def get_market_sensitivity(returns_series: pd.Series, market_returns: pd.Series, frequence: str = \"daily\"):\n",
    "    \"\"\"\n",
    "    - Beta: Sensitivity to market movements.\n",
    "    - Alpha: Risk-adjusted return above the market return.\n",
    "    - Upside/Downside Capture Ratios: Percent of market gains or losses captured by the investment.\n",
    "    - Tracking Error: Volatility of return differences from the market.\n",
    "    \"\"\"\n",
    "    # ======= I. Get the right frequence =======\n",
    "    frequence_dict = {\"daily\": 252, \"5m\": 19656, \"1m\": 98280}\n",
    "    adjusted_frequence = frequence_dict[frequence]\n",
    "    \n",
    "    # ======= II. Compute the statistics =======\n",
    "    # ------ Beta and Alpha (Jensens's)\n",
    "    beta = returns_series.cov(market_returns) / market_returns.var()\n",
    "    alpha = returns_series.mean() * adjusted_frequence - beta * (market_returns.mean() * adjusted_frequence)\n",
    "    \n",
    "    # ------ Capture Ratios\n",
    "    upside_capture = returns_series[market_returns > 0].mean() / market_returns[market_returns > 0].mean()\n",
    "    downside_capture = returns_series[market_returns < 0].mean() / market_returns[market_returns < 0].mean()\n",
    "\n",
    "    # ------ Tracking Error\n",
    "    tracking_error = returns_series.sub(market_returns).std() * np.sqrt(adjusted_frequence)\n",
    "    \n",
    "    # ======= III. Store the statistics =======\n",
    "    market_sensitivity_stats = {\n",
    "        \"beta\": beta,\n",
    "        \"alpha\": alpha,\n",
    "        \"upside_capture\": upside_capture,\n",
    "        \"downside_capture\": downside_capture,\n",
    "        \"tracking_error\": tracking_error,\n",
    "    }\n",
    "    \n",
    "    return market_sensitivity_stats\n",
    "\n",
    "# ____________________________________________________________________________________ #\n",
    "def get_performance_measures(returns_series: pd.Series, market_returns: pd.Series, risk_free_rate: float = 0.0, frequence: str = \"daily\"):\n",
    "    \"\"\"\n",
    "    - Sharpe Ratio: Risk-adjusted returns per unit of volatility.\n",
    "    - Sortino Ratio: Risk-adjusted return accounting only for downside volatility.\n",
    "    - Treynor Ratio: Return per unit of systematic (market) risk.\n",
    "    - Information Ratio: Excess return per unit of tracking error.\n",
    "    - Sterling Ratio: Return per unit of average drawdown.\n",
    "    - Calmar Ratio: Return per unit of maximum drawdown.\n",
    "    \"\"\"\n",
    "    # ======= I. Get the right frequence =======\n",
    "    frequence_dict = {\"daily\": 252, \"5m\": 19656, \"1m\": 98280}\n",
    "    adjusted_frequence = frequence_dict[frequence]\n",
    "    \n",
    "    # ======= II. Extract Statistics =======\n",
    "    distribution_stats = get_distribution(returns_series, frequence)\n",
    "    expected_return = distribution_stats[\"expected_return\"]\n",
    "    volatility = distribution_stats[\"volatility\"]\n",
    "    downside_deviation = distribution_stats[\"downside_deviation\"]\n",
    "    \n",
    "    risk_stats = get_risk_measures(returns_series)\n",
    "    drawdown = risk_stats[\"drawdown\"]\n",
    "    maximum_drawdown = risk_stats[\"maximum_drawdown\"]\n",
    "    \n",
    "    market_sensitivity_stats = get_market_sensitivity(returns_series, market_returns, frequence)\n",
    "    beta = market_sensitivity_stats[\"beta\"]\n",
    "    tracking_error = market_sensitivity_stats[\"tracking_error\"]\n",
    "    \n",
    "    # ======= III. Compute the ratios =======\n",
    "    # ------ Sharpe, Sortino, Treynor, and Information Ratios\n",
    "    sharpe_ratio = (expected_return - risk_free_rate) / volatility if volatility != 0 else 0\n",
    "    sortino_ratio = expected_return / downside_deviation if downside_deviation != 0 else 0\n",
    "    treynor_ratio = expected_return / beta if beta != 0 else 0\n",
    "    information_ratio = (expected_return - market_returns.mean() * adjusted_frequence) / tracking_error if tracking_error != 0 else 0\n",
    "\n",
    "    # ------ Sterling, and Calmar Ratios\n",
    "    average_drawdown = abs(drawdown[drawdown < 0].mean()) if drawdown[drawdown < 0].sum() != 0 else 0\n",
    "    sterling_ratio = (expected_return - risk_free_rate) / average_drawdown if average_drawdown != 0 else 0\n",
    "    calmar_ratio = expected_return / abs(maximum_drawdown) if maximum_drawdown != 0 else 0\n",
    "    \n",
    "    # ======= IV. Store the statistics =======\n",
    "    performance_stats = {\n",
    "        \"sharpe_ratio\": sharpe_ratio,\n",
    "        \"sortino_ratio\": sortino_ratio,\n",
    "        \"treynor_ratio\": treynor_ratio,\n",
    "        \"information_ratio\": information_ratio,\n",
    "        \"sterling_ratio\": sterling_ratio,\n",
    "        \"calmar_ratio\": calmar_ratio,\n",
    "    }\n",
    "    \n",
    "    return performance_stats, (distribution_stats, risk_stats, market_sensitivity_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we can define a Backtest class. This class will be used to run the backtest of a given strategy.\n",
    "\"\"\"\n",
    "\n",
    "class Backtest():\n",
    "    def __init__(self, strategy: Strategy, brokerage_cost: float = 0.0, slippage_cost: float = 0.0):\n",
    "        # ======= Backtest parameters =======\n",
    "        self.ticker = None\n",
    "        self.start_date = None\n",
    "        self.end_date = None\n",
    "        self.strategy_params = None\n",
    "        \n",
    "        self.brokerage_cost = brokerage_cost\n",
    "        self.slippage_cost = slippage_cost\n",
    "        \n",
    "        self.n_jobs = 1\n",
    "        \n",
    "        # ======= Strategy inputs=======\n",
    "        self.strategy = strategy\n",
    "        self.data = None\n",
    "        self.processed_data = None\n",
    "\n",
    "        # ======= Backtest results =======\n",
    "        self.signals_dfs = None\n",
    "        self.operations_dfs = None\n",
    "        self.full_operations_df = None\n",
    "        self.full_signals_df = None\n",
    "\n",
    "    #*____________________________________________________________________________________ #\n",
    "    def set_computingParams(self, date_name: str, bid_open_name: str, ask_open_name: str, n_jobs: int = 1):\n",
    "        \"\"\"\n",
    "        This method is used to set the different parameters to ensure the correct computation of the operations.\n",
    "        \n",
    "            - date_name (str) : name of the column containing the dates\n",
    "            - bid_open_name (str) : name of the column containing the bid open prices at which the strategy will operate\n",
    "            - ask_open_name (str) : name of the column containing the ask open prices at which the strategy will operate\n",
    "            - n_jobs (int) : number of jobs to run in parallel\n",
    "        \"\"\"\n",
    "        self.strategy.set_names(date_name=date_name, bid_open_name=bid_open_name, ask_open_name=ask_open_name)\n",
    "        self.n_jobs = n_jobs\n",
    "    \n",
    "    #*____________________________________________________________________________________ #\n",
    "    def set_backtestParams(self, ticker: str, start_date: str, end_date: str, strategy_params: dict):\n",
    "        \"\"\"\n",
    "        This method is used to set the different parameters of the backtest.\n",
    "        \n",
    "            - ticker (str) : ticker of the asset to backtest\n",
    "            - start_date (str) : start date of the backtest\n",
    "            - end_date (str) : end date of the backtest\n",
    "            - strategy_params (dict) : parameters of the strategy\n",
    "        \"\"\"\n",
    "        self.ticker = ticker\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.strategy_params = strategy_params\n",
    "    \n",
    "    #*____________________________________________________________________________________ #\n",
    "    def run_strategy(self):\n",
    "        \"\"\"\n",
    "        This method is used to run the strategy and extract the operations.\n",
    "        \"\"\"\n",
    "        # ======= I. Set up Parameters and Data =======\n",
    "        self.strategy.set_params(**self.strategy_params)\n",
    "        data = self.strategy.load_data(self.ticker, self.start_date, self.end_date)\n",
    "        processed_data = self.strategy.process_data()\n",
    "        \n",
    "        # I.2 Store the data\n",
    "        self.data = data\n",
    "        self.processed_data = processed_data\n",
    "        \n",
    "        # ======= II. Run the Strategy =======\n",
    "        if self.n_jobs > 1:\n",
    "            #! Be aware that the strategy should be thread-safe and to keep track of the timestamps to reconstitute the operations later.\n",
    "            operations_dfs, signals_dfs = Parallel(n_jobs=self.n_jobs)(delayed(self.strategy.operate)(data_group) for data_group in processed_data)\n",
    "        else:\n",
    "            operations_dfs = []\n",
    "            signals_dfs = []\n",
    "            for data_group in processed_data:\n",
    "                operations_df, signals_df = self.strategy.operate(data_group)\n",
    "                operations_dfs.append(operations_df)\n",
    "                signals_dfs.append(signals_df)\n",
    "        \n",
    "        full_operations_df = pd.concat(operations_dfs, ignore_index=True, axis=0)\n",
    "        full_signals_df = pd.concat(signals_dfs, ignore_index=True, axis=0)\n",
    "        \n",
    "        return full_operations_df, full_signals_df, operations_dfs, signals_dfs\n",
    "    \n",
    "    #*____________________________________________________________________________________ #\n",
    "    def apply_slippage(self, operations_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        This method is used to apply the slippage on the operations by modifying the entry and exit prices.\n",
    "        \n",
    "            - operations_df (pd.DataFrame) : DataFrame containing the operations\n",
    "        \"\"\"\n",
    "        # ======= I. Ensure there are operations =======\n",
    "        adjusted_operations_df = operations_df.copy()\n",
    "        if operations_df.empty:\n",
    "            return adjusted_operations_df\n",
    "\n",
    "        # ======= II. Apply slippage on Entry/Exit prices =======\n",
    "        # II.1 Adjust entry prices\n",
    "        adjusted_operations_df[\"Entry_Price_Adjusted\"] = adjusted_operations_df.apply(\n",
    "            lambda row: row[\"Entry_Price\"] * (1 + self.slippage_cost) if row[\"Side\"] == 1 else row[\"Entry_Price\"] * (1 - self.slippage_cost), axis=1\n",
    "        )\n",
    "\n",
    "        # II.2 Adjust exit prices\n",
    "        adjusted_operations_df[\"Exit_Price_Adjusted\"] = adjusted_operations_df.apply(\n",
    "            lambda row: row[\"Exit_Price\"] * (1 - self.slippage_cost) if row[\"Side\"] == 1 else row[\"Exit_Price\"] * (1 + self.slippage_cost), axis=1\n",
    "        )\n",
    "\n",
    "        # ======= III. Adjust the PnL =======\n",
    "        adjusted_operations_df[\"PnL_Adjusted\"] = (adjusted_operations_df[\"Exit_Price_Adjusted\"] - adjusted_operations_df[\"Entry_Price_Adjusted\"]) * adjusted_operations_df[\"Side\"]\n",
    "\n",
    "        return adjusted_operations_df\n",
    "    \n",
    "    #*____________________________________________________________________________________ #\n",
    "    def apply_brokerage(self, operations_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        This method is used to apply the brokerage cost on the operations by modifying the PnL.\n",
    "        \n",
    "            - operations_df (pd.DataFrame) : DataFrame containing the operations\n",
    "        \"\"\"\n",
    "        # ======= I. Ensure there are operations =======\n",
    "        adjusted_operations_df = operations_df.copy()\n",
    "        if operations_df.empty:\n",
    "            return adjusted_operations_df\n",
    "\n",
    "        # ======= II. Apply brokerage on PnL =======\n",
    "        adjusted_operations_df[\"PnL_Adjusted\"] = adjusted_operations_df[\"PnL_Adjusted\"] - (self.brokerage_cost * np.abs(adjusted_operations_df[\"Entry_Price\"]))\n",
    "\n",
    "        return adjusted_operations_df\n",
    "\n",
    "    #*____________________________________________________________________________________ #\n",
    "    def run_backtest(self):\n",
    "        \"\"\"\n",
    "        This method is used to run the backtest.\n",
    "        \"\"\"\n",
    "        # ======= I. Run the Strategy =======\n",
    "        full_operations_df, full_signals_df, operations_dfs, signals_dfs = self.run_strategy()\n",
    "        full_operations_df = self.apply_slippage(full_operations_df)\n",
    "        full_operations_df = self.apply_brokerage(full_operations_df)\n",
    "        \n",
    "        # ======= II. Compute the Cumulative Returns : Operations bars =======\n",
    "        # II.1 Without Fees\n",
    "        full_operations_df['NoFees_strategy_returns'] = full_operations_df['PnL'] / full_operations_df['Entry_Price']\n",
    "        full_operations_df['NoFees_strategy_cumret'] = (1 + full_operations_df['NoFees_strategy_returns']).cumprod()\n",
    "        \n",
    "        # II.2 With Fees\n",
    "        full_operations_df['strategy_returns'] = full_operations_df['PnL_Adjusted'] / full_operations_df['Entry_Price']\n",
    "        full_operations_df['strategy_cumret'] = (1 + full_operations_df['strategy_returns']).cumprod()\n",
    "        \n",
    "        # II.3 Buy and Hold\n",
    "        full_operations_df['BuyAndHold_returns'] = (full_operations_df['Exit_Price'] - full_operations_df['Entry_Price']) / full_operations_df['Entry_Price']\n",
    "        full_operations_df['BuyAndHold_cumret'] = (1 + full_operations_df['BuyAndHold_returns']).cumprod()\n",
    "\n",
    "        # ======= III. Compute the Cumulative Returns : Time bars =======\n",
    "        # For this part, we don't consider the fees and slippage as this computation is relevant only for very low frequency strategies which are less impacted by these costs.\n",
    "        name_series = self.strategy.ask_open_name\n",
    "        full_signals_df['BuyAndHold_returns'] = (full_signals_df[name_series].shift(-1) - full_signals_df[name_series]) / full_signals_df[name_series]\n",
    "        full_signals_df['BuyAndHold_cumret'] = (1 + full_signals_df['BuyAndHold_returns']).cumprod()\n",
    "        full_signals_df['strategy_returns'] = full_signals_df['signal'].shift(-1) * full_signals_df['BuyAndHold_returns']\n",
    "        full_signals_df['strategy_cumret'] = (1 + full_signals_df['strategy_returns']).cumprod()\n",
    "\n",
    "         # ======= IV. Compute statistics =======\n",
    "        returns_series = full_operations_df['strategy_returns']\n",
    "        market_returns = full_operations_df['BuyAndHold_returns']\n",
    "        operation_stats, _ = get_performance_measures(returns_series, market_returns, frequence=\"daily\")\n",
    "\n",
    "        returns_series = full_signals_df['strategy_returns']\n",
    "        market_returns = full_signals_df['BuyAndHold_returns']\n",
    "        time_stats, _ = get_performance_measures(returns_series, market_returns, frequence=\"daily\")\n",
    "        \n",
    "        # ======= IV. Store the results =======\n",
    "        self.full_operations_df = full_operations_df\n",
    "        self.full_signals_df = full_signals_df\n",
    "        self.operations_dfs = operations_dfs\n",
    "        self.signals_dfs = signals_dfs\n",
    "        \n",
    "        return full_operations_df, full_signals_df, operation_stats, time_stats\n",
    "        \n",
    "    #*____________________________________________________________________________________ #\n",
    "    def plot_operationsBars(self, by_date: bool = False, BuyAndHold: bool = True, NoFees: bool = True, Fees: bool = True):\n",
    "        \"\"\"\n",
    "        Plots the strategy's cumulative returns based on executed trades.  \n",
    "        This method intentionally excludes daily portfolio valuation to avoid overestimating result significance.\n",
    "        \"\"\"\n",
    "        # ======= I. Prepare the DataFrame for plotting =======\n",
    "        plotting_df = self.full_operations_df.copy()\n",
    "\n",
    "        # ======= II. Initialize the plot =======\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        colors = sns.color_palette(\"husl\", 3)\n",
    "        plt.figure(figsize=(17, 6))\n",
    "        \n",
    "        if by_date:\n",
    "            plotting_df = plotting_df.set_index(plotting_df['Entry_Date'])\n",
    "            plt.xlabel('Date', fontsize=14, fontweight='bold')\n",
    "        else:\n",
    "            plt.xlabel('Number of Trades', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.ylabel('Cumulative Returns', fontsize=14, fontweight='bold')\n",
    "        plt.title('Strategy Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "        # ======= III. Plot the Cumulative Returns =======\n",
    "        if BuyAndHold:\n",
    "            plt.plot(plotting_df['BuyAndHold_cumret'], label='Buy and Hold', color=colors[0], linewidth=2)\n",
    "        if NoFees:\n",
    "            plt.plot(plotting_df['NoFees_strategy_cumret'], label='Cumulative Returns Without Fees', color=colors[1], linestyle='--', linewidth=1)\n",
    "        if Fees:\n",
    "            plt.plot(plotting_df['strategy_cumret'], label='Cumulative Returns Adjusted', color=colors[2], linewidth=2)\n",
    "\n",
    "        plt.legend(fontsize=12, loc='best', frameon=True, shadow=True)\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.show()\n",
    "    \n",
    "    #*____________________________________________________________________________________ #\n",
    "    def plot_timeBars(self):\n",
    "        \"\"\"\n",
    "        This method is used to plot the strategy's cumulative returns based on time bars.\n",
    "        \"\"\"\n",
    "        # ======= I. Prepare the DataFrame for plotting =======\n",
    "        date_name = self.strategy.date_name\n",
    "        plotting_df = self.full_signals_df.copy()\n",
    "        plotting_df = plotting_df.set_index(plotting_df[date_name])\n",
    "\n",
    "        # ======= II. Initialize the plot =======\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        colors = sns.color_palette(\"husl\", 3)\n",
    "        plt.figure(figsize=(17, 6))\n",
    "        \n",
    "        plt.xlabel('Date', fontsize=14, fontweight='bold')\n",
    "        plt.ylabel('Cumulative Returns', fontsize=14, fontweight='bold')\n",
    "        plt.title('Strategy Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "        # ======= III. Plot the Cumulative Returns =======\n",
    "        plt.plot(plotting_df['BuyAndHold_cumret'], label='Buy and Hold', color=colors[0], linewidth=2)\n",
    "        plt.plot(plotting_df['strategy_cumret'], label='Cumulative Returns Adjusted', color=colors[2], linewidth=2)\n",
    "\n",
    "        plt.legend(fontsize=12, loc='best', frameon=True, shadow=True)\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CartesiusResolved",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
