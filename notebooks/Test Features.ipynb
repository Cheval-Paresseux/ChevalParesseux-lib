{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import Data as dt\n",
    "import ChevalParesseux_lib as lib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Sets the number of jobs to use for parallel processing\n",
    "n_jobs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I. Load data\n",
    "data = dt.load_data(ticker='SPY')\n",
    "data['code'] = 'SPY'\n",
    "\n",
    "# II. Making Samples (we use a temporal sampling here)\n",
    "full_size = len(data)\n",
    "\n",
    "training_data = data.iloc[0 : int(full_size * 0.7)].copy()\n",
    "testing_data = data.loc[int(full_size * 0.7) + 1 : int(full_size * 0.9)].copy()\n",
    "embargo_data = data.loc[int(full_size * 0.9) + 1 :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = training_data.copy()\n",
    "\n",
    "# ======= I. Set up the labeller =======\n",
    "labeller = lib.TripleBarrier_labeller(n_jobs=n_jobs)\n",
    "labeller_params = {\n",
    "    \"upper_barrier\": [1.5],\n",
    "    \"lower_barrier\": [1],\n",
    "    \"vertical_barrier\": [21],\n",
    "    \"vol_window\": [21],\n",
    "    \"smoothing_method\": ['ewma'],\n",
    "    \"window_smooth\": [5],\n",
    "    \"lambda_smooth\": [0.2],\n",
    "}\n",
    "labeller.set_params(**labeller_params)\n",
    "\n",
    "# ======= II. Extract the labels =======\n",
    "labels_df = labeller.extract(data=processed_train['close'])\n",
    "processed_train['label'] = labels_df[labels_df.columns[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Features Extraction***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, Self\n",
    "from abc import ABC, abstractmethod\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "#! ==================================================================================== #\n",
    "#! ================================= Base Model ======================================= #\n",
    "class Feature(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for all features.\n",
    "    \n",
    "    This class defines the core structure and interface for feature extraction. It is meant to be subclassed\n",
    "    by specific feature implementations. \n",
    "    Subclasses must implement the following abstract methods:\n",
    "        - __init__: Initializes the feature with name, and optionally number of jobs.\n",
    "        - set_params: Defines the parameter grid as a dictionary of lists.\n",
    "        - process_data: Applies preprocessing to the data.\n",
    "        - get_feature: Extracts the actual feature(s), returning a DataFrame.\n",
    "\n",
    "    Main usage involves one core methods:\n",
    "        - smooth_data: Applies optional smoothing to the input data before feature computation.\n",
    "        - extract: Returns extracted features.\n",
    "    \"\"\"\n",
    "    #?_____________________________ Initialization methods _______________________________ #\n",
    "    @abstractmethod\n",
    "    def __init__(\n",
    "        self, \n",
    "        name: str, \n",
    "        n_jobs: int = 1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Constructor for the Feature class.\n",
    "        \n",
    "        Parameters:\n",
    "            - name (str): The name identifier for the feature.\n",
    "            - n_jobs (int): Number of parallel jobs to use during feature computation.\n",
    "        \"\"\"\n",
    "        # ======= I. Initialize Class =======\n",
    "        self.name = name\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        # ======= II. Initialize Auxilaries =======\n",
    "        self.params = {}\n",
    "    \n",
    "    #?____________________________________________________________________________________ #\n",
    "    @abstractmethod\n",
    "    def set_params(\n",
    "        self,\n",
    "        **kwargs\n",
    "    ) -> Self:\n",
    "        \"\"\"\n",
    "        Sets the parameter grid for the feature extraction.\n",
    "\n",
    "        Parameters:\n",
    "            - **kwargs: Each parameter should be a list of possible values.\n",
    "                    Example: feature.set_params(window=[5, 10], threshold=[3, 4])\n",
    "\n",
    "        Returns:\n",
    "            - Self: The instance of the class with the parameter grid set.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    #?________________________________ Auxiliary methods _________________________________ #\n",
    "    @abstractmethod\n",
    "    def process_data(\n",
    "        self,\n",
    "        data: Union[tuple, pd.Series, pd.DataFrame],\n",
    "        **kwargs\n",
    "    ) -> Union[tuple, pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        Preprocesses the data before feature extraction.\n",
    "\n",
    "        Parameters:\n",
    "            - data (tuple | pd.Series | pd.DataFrame): The input data to be processed.\n",
    "            - **kwargs: Additional parameters for the data processing.\n",
    "\n",
    "        Returns:\n",
    "            - tuple or pd.DataFrame or pd.Series: The processed data ready for feature extraction.\n",
    "        \"\"\"\n",
    "        ...\n",
    "    \n",
    "    #?____________________________________________________________________________________ #\n",
    "    @abstractmethod\n",
    "    def get_feature(\n",
    "        self,\n",
    "        data: Union[tuple, pd.Series, pd.DataFrame],\n",
    "        **kwargs\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Core method for feature extraction.\n",
    "        \n",
    "        Parameters:\n",
    "            - data (tuple | pd.Series | pd.DataFrame): The input data to extract the feature from\n",
    "            - **kwargs: Additional parameters for the feature extraction.\n",
    "        \n",
    "        Returns:\n",
    "            - pd.Series : The extracted feature as a pd.Series.\n",
    "        \"\"\"\n",
    "        ...\n",
    "       \n",
    "    #?____________________________________________________________________________________ #\n",
    "    def smooth_data(\n",
    "        self, \n",
    "        data: pd.Series,\n",
    "        smoothing_method: str = None, \n",
    "        window_smooth: int = None, \n",
    "        lambda_smooth: float = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Applies optional smoothing to the input data before feature computation.\n",
    "\n",
    "        Parameters:\n",
    "            - data (pd.Series): The input data to be processed.\n",
    "            - smoothing_method (str): Type of smoothing to apply. Options: \"ewma\", \"average\", or None.\n",
    "            - window_smooth (int): Size of the smoothing window.\n",
    "            - lambda_smooth (float): EWMA decay parameter in [0, 1].\n",
    "\n",
    "        Returns:\n",
    "            - smoothed_data (pd.Series): The smoothed series, or raw series if no smoothing is applied.\n",
    "        \"\"\"\n",
    "        # ======= I. Check if any smoothing should be applied =======\n",
    "        if smoothing_method is None:\n",
    "            return data\n",
    "        \n",
    "        # ======= II. Compute the smoothed series =======\n",
    "        elif smoothing_method == \"ewma\":\n",
    "            smoothed_data = lib.ewma_smoothing(price_series=data, window=window_smooth, ind_lambda=lambda_smooth)\n",
    "        elif smoothing_method == \"average\":\n",
    "            smoothed_data = lib.average_smoothing(price_series=data, window=window_smooth)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Smoothing method not recognized\")\n",
    "        \n",
    "        return smoothed_data\n",
    "    \n",
    "    #?_________________________________ Callable methods _________________________________ #\n",
    "    def extract(\n",
    "        self, \n",
    "        data: Union[tuple, pd.Series, pd.DataFrame]\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Main method to extract features.\n",
    "\n",
    "        Parameters:\n",
    "            - data (tuple | pd.Series | pd.DataFrame): The input data to extract the feature from\n",
    "        \n",
    "        Returns:\n",
    "            - features_df (pd.DataFrame): The extracted features as a DataFrame.\n",
    "        \"\"\"\n",
    "        # ======= I. Extract the Parameters Universe =======\n",
    "        params_grid = lib.get_dict_universe(self.params)\n",
    "\n",
    "        # ======= II. Extract the features for each Parameters =======\n",
    "        features = Parallel(n_jobs=self.n_jobs)(delayed(self.get_feature)(data, **params) for params in params_grid)\n",
    "\n",
    "        # ======= III. Create a DataFrame with the features =======\n",
    "        features_df = pd.concat(features, axis=1)\n",
    "\n",
    "        return features_df\n",
    "\n",
    "#! ================================= Example ======================================= #\n",
    "class Average_feature(Feature):\n",
    "    \"\"\"\n",
    "    Moving Average Feature\n",
    "\n",
    "    This class computes the normalized moving average of a time series, with optional pre-smoothing filters.\n",
    "    It inherits from the Feature base class and implements methods to:\n",
    "        - set_params : define parameter grids.\n",
    "        - process_data : optionally performs preprocessing on the input series.\n",
    "        - get_feature : compute the moving average feature over a rolling window\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        name: str = \"average\" , \n",
    "        n_jobs: int = 1\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the average_feature object with input data, name, and parallel jobs.\n",
    "        \n",
    "        Parameters:\n",
    "            - name (str): Name of the feature, used in column labeling.\n",
    "            - n_jobs (int): Number of jobs to run in parallel for feature extraction.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            name=name, \n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "    \n",
    "    #?____________________________________________________________________________________ #\n",
    "    def set_params(\n",
    "        self,\n",
    "        window: list = [5, 10, 30, 60],\n",
    "        smoothing_method: list = [None, \"ewma\", \"average\"],\n",
    "        window_smooth: list = [5, 10],\n",
    "        lambda_smooth: list = [0.1, 0.2, 0.5],\n",
    "    ) -> Self:\n",
    "        \"\"\"\n",
    "        Defines the parameter grid for feature extraction.\n",
    "\n",
    "        Parameters:\n",
    "            - window (list): Rolling window sizes for the moving average.\n",
    "            - smoothing_method (list): Type of pre-smoothing to apply. Options: None, \"ewma\", \"average\".\n",
    "            - window_smooth (list): Window size for smoothing methods.\n",
    "            - lambda_smooth (list): Smoothing factor for EWMA, in [0, 1].\n",
    "        \"\"\"\n",
    "        self.params = {\n",
    "            \"window\": window,\n",
    "            \"smoothing_method\": smoothing_method,\n",
    "            \"window_smooth\": window_smooth,\n",
    "            \"lambda_smooth\": lambda_smooth,\n",
    "        }\n",
    "\n",
    "        return self\n",
    "\n",
    "    #?____________________________________________________________________________________ #\n",
    "    def process_data(\n",
    "        self, \n",
    "        data: pd.Series,\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Applies preprocessing to the input data before feature extraction.\n",
    "        \n",
    "        Parameters:\n",
    "            - data (pd.Series): The input data to be processed.\n",
    "        \n",
    "        Returns:\n",
    "            - processed_data (pd.Series): The resetted index series.\n",
    "        \"\"\"\n",
    "        processed_data = data.copy()\n",
    "        processed_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return processed_data\n",
    "    \n",
    "    #?____________________________________________________________________________________ #\n",
    "    def get_feature(\n",
    "        self,\n",
    "        data: pd.Series,\n",
    "        window: int,\n",
    "        smoothing_method: str,\n",
    "        window_smooth: int,\n",
    "        lambda_smooth: float,\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Computes the normalized rolling average of the processed series.\n",
    "\n",
    "        Parameters: \n",
    "            - data (pd.Series): The input series to be processed.\n",
    "            - window (int): Rolling window size for the moving average.\n",
    "            - smoothing_method (str): Smoothing method used.\n",
    "            - window_smooth (int): Smoothing window size.\n",
    "            - lambda_smooth (float): Smoothing parameter for EWMA.\n",
    "\n",
    "        Returns:\n",
    "            - rolling_average (pd.Series): The resulting normalized moving average feature.\n",
    "        \"\"\"\n",
    "        # ======= I. Smooth the Data & Preprocess =======\n",
    "        smoothed_series = self.smooth_data(\n",
    "            data=data, \n",
    "            smoothing_method=smoothing_method, \n",
    "            window_smooth=window_smooth, \n",
    "            lambda_smooth=lambda_smooth\n",
    "        )\n",
    "        \n",
    "        processed_series = self.process_data(data=smoothed_series)\n",
    "\n",
    "        # ======= II. Compute the moving average =======\n",
    "        rolling_average = processed_series.rolling(window=window).apply(np.mean, raw=False)\n",
    "\n",
    "        # ======= III. Convert to pd.Series and Center =======\n",
    "        rolling_average = (pd.Series(rolling_average, index=processed_series.index) / (processed_series + 1e-8)) - 1\n",
    "        \n",
    "        # ======= IV. Change Name =======\n",
    "        rolling_average.name = f\"{self.name}_{window}_{smoothing_method}_{window_smooth}_{lambda_smooth}\"\n",
    "        rolling_average.index = data.index\n",
    "\n",
    "        return rolling_average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_params = {\n",
    "    \"window\": [5, 10, 20, 50],\n",
    "    \"smoothing_method\": [None, 'ewma'],\n",
    "    \"window_smooth\": [5],\n",
    "    \"lambda_smooth\": [0.2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kama_feature(Feature):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        name: str = \"kama\" , \n",
    "        n_jobs: int = 1\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "    \n",
    "    #?____________________________________________________________________________________ #\n",
    "    def set_params(\n",
    "        self,\n",
    "        window: list = [5, 10, 30, 60],\n",
    "        smoothing_method: list = [None, \"ewma\", \"average\"],\n",
    "        window_smooth: list = [5, 10],\n",
    "        lambda_smooth: list = [0.1, 0.2, 0.5],\n",
    "        fastest_window: list = [2, 5, 10],\n",
    "        slowest_window: list = [20, 30],\n",
    "    ) -> Self:\n",
    "        \"\"\"\n",
    "        Sets the parameter grid for momentum feature extraction.\n",
    "\n",
    "        Parameters:\n",
    "            - window (list): Rolling window sizes for momentum calculation.\n",
    "            - smoothing_method (list): Type of smoothing to apply before calculation.\n",
    "            - window_smooth (list): Smoothing window sizes.\n",
    "            - lambda_smooth (list): Decay factors for EWMA.\n",
    "        \"\"\"\n",
    "        self.params = {\n",
    "            \"window\": window,\n",
    "            \"smoothing_method\": smoothing_method,\n",
    "            \"window_smooth\": window_smooth,\n",
    "            \"lambda_smooth\": lambda_smooth,\n",
    "            \"fastest_window\": fastest_window,\n",
    "            \"slowest_window\": slowest_window,\n",
    "        }\n",
    "\n",
    "        return self\n",
    "\n",
    "    #?____________________________________________________________________________________ #\n",
    "    def process_data(\n",
    "        self, \n",
    "        data: pd.Series,\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        processed_data = data.copy()\n",
    "        processed_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return processed_data\n",
    "    \n",
    "    #?____________________________________________________________________________________ #\n",
    "    def get_feature(\n",
    "        self,\n",
    "        data: pd.Series,\n",
    "        window: int,\n",
    "        smoothing_method: str,\n",
    "        window_smooth: int,\n",
    "        lambda_smooth: float,\n",
    "        fastest_window: int,\n",
    "        slowest_window: int,\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # ======= I. Smooth the Data & Preprocess =======\n",
    "        smoothed_series = self.smooth_data(\n",
    "            data=data, \n",
    "            smoothing_method=smoothing_method, \n",
    "            window_smooth=window_smooth, \n",
    "            lambda_smooth=lambda_smooth\n",
    "        )\n",
    "        \n",
    "        processed_series = self.process_data(data=smoothed_series)\n",
    "\n",
    "        # ======= II. Compute the moving momentum =======\n",
    "        rolling_kama = processed_series.rolling(window=window ).apply(get_kama, args=(fastest_window, slowest_window), raw=False)\n",
    "        \n",
    "        # ======= III. Convert to pd.Series and Center =======\n",
    "        rolling_kama = (pd.Series(rolling_kama, index=processed_series.index) / (processed_series + 1e-8)) - 1\n",
    "        \n",
    "        # ======= IV. Change Name =======\n",
    "        rolling_kama.name = f\"{self.name}_f{fastest_window}_s{slowest_window}_{window}_{smoothing_method}_{window_smooth}_{lambda_smooth}\"\n",
    "        rolling_kama.index = data.index\n",
    "\n",
    "        return rolling_kama\n",
    "\n",
    "#*_____________________________________________________________________________________ #\n",
    "def get_kama(\n",
    "    series: pd.Series,\n",
    "    fastest_window: int,\n",
    "    slowest_window: int,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Efficiently compute the last value of KAMA using the last two values only.\n",
    "    \n",
    "    Parameters:\n",
    "        series (pd.Series): Price series.\n",
    "        fastest_window (int): Fastest EMA window.\n",
    "        slowest_window (int): Slowest EMA window.\n",
    "    \n",
    "    Returns:\n",
    "        float: The last KAMA value.\n",
    "    \"\"\"\n",
    "    # ======= I. Inputs =======  \n",
    "    slowest_window = min(slowest_window, len(series) - 2)\n",
    "    \n",
    "    fast_sc = 2 / (fastest_window + 1)\n",
    "    slow_sc = 2 / (slowest_window + 1)\n",
    "    \n",
    "    # ======= II. Compute KAMA value for t-1 =======\n",
    "    change_t0 = abs(series.iloc[-2] - series.iloc[-2 - slowest_window])\n",
    "    vol_t0 = series.diff().abs().iloc[-2 - slowest_window + 1 : -1].sum()\n",
    "    efficiency_ratio_t0 = change_t0 / (vol_t0 + 1e-8)\n",
    "\n",
    "    smoothing_constant_t0 = (efficiency_ratio_t0 * (fast_sc - slow_sc) + slow_sc) ** 2\n",
    "    kama_t0 = series.iloc[-3] + smoothing_constant_t0 * (series.iloc[-2] - series.iloc[-3])\n",
    "\n",
    "    # ======= III. Compute KAMA value for t =======\n",
    "    change_t1 = abs(series.iloc[-1] - series.iloc[-1 - slowest_window])\n",
    "    vol_t1 = series.diff().abs().iloc[-1 - slowest_window + 1 :].sum()\n",
    "    efficiency_ratio_t1 = change_t1 / (vol_t1 + 1e-8)\n",
    "\n",
    "    smoothing_constant_t1 = (efficiency_ratio_t1 * (fast_sc - slow_sc) + slow_sc) ** 2\n",
    "    kama_t1 = kama_t0 + smoothing_constant_t1 * (series.iloc[-1] - kama_t0)\n",
    "\n",
    "    return kama_t1\n",
    "\n",
    "#!_____________________________________________________________________________________ #\n",
    "kama_feature = Kama_feature(n_jobs=n_jobs)\n",
    "kama_params = {\n",
    "    \"window\": [20, 50],\n",
    "    \"smoothing_method\": [None, 'ewma'],\n",
    "    \"window_smooth\": [5],\n",
    "    \"lambda_smooth\": [0.2],\n",
    "    \"fastest_window\": [2, 5, 10],\n",
    "    \"slowest_window\": [20, 30],\n",
    "}\n",
    "kama_feature.set_params(**kama_params)\n",
    "\n",
    "kama_feature_df = kama_feature.extract(data=processed_train['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticRSI_feature(Feature):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        name: str = \"stochastic_rsi\", \n",
    "        n_jobs: int = 1\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "    \n",
    "    #?____________________________________________________________________________________ #\n",
    "    def set_params(\n",
    "        self,\n",
    "        window: list = [5, 10, 30, 60],\n",
    "        smoothing_method: list = [None, \"ewma\", \"average\"],\n",
    "        window_smooth: list = [5, 10],\n",
    "        lambda_smooth: list = [0.1, 0.2, 0.5],\n",
    "    ) -> Self:\n",
    "        \"\"\"\n",
    "        Sets the parameter grid for momentum feature extraction.\n",
    "\n",
    "        Parameters:\n",
    "            - window (list): Rolling window sizes for momentum calculation.\n",
    "            - smoothing_method (list): Type of smoothing to apply before calculation.\n",
    "            - window_smooth (list): Smoothing window sizes.\n",
    "            - lambda_smooth (list): Decay factors for EWMA.\n",
    "        \"\"\"\n",
    "        self.params = {\n",
    "            \"window\": window,\n",
    "            \"smoothing_method\": smoothing_method,\n",
    "            \"window_smooth\": window_smooth,\n",
    "            \"lambda_smooth\": lambda_smooth,\n",
    "        }\n",
    "\n",
    "        return self\n",
    "\n",
    "    #?____________________________________________________________________________________ #\n",
    "    def process_data(\n",
    "        self, \n",
    "        data: pd.Series,\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        processed_data = data.copy()\n",
    "        processed_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return processed_data\n",
    "    \n",
    "    #?____________________________________________________________________________________ #\n",
    "    def get_feature(\n",
    "        self,\n",
    "        data: pd.Series,\n",
    "        window: int,\n",
    "        smoothing_method: str,\n",
    "        window_smooth: int,\n",
    "        lambda_smooth: float,\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # ======= I. Smooth the Data & Preprocess =======\n",
    "        smoothed_series = self.smooth_data(\n",
    "            data=data, \n",
    "            smoothing_method=smoothing_method, \n",
    "            window_smooth=window_smooth, \n",
    "            lambda_smooth=lambda_smooth\n",
    "        )\n",
    "        \n",
    "        processed_series = self.process_data(data=smoothed_series)\n",
    "\n",
    "        # ======= II. Compute the moving momentum =======\n",
    "        rolling_stoch_rsi = processed_series.rolling(window=window ).apply(get_stochastic_rsi, raw=False)\n",
    "        \n",
    "        # ======= III. Convert to pd.Series and Center =======\n",
    "        rolling_stoch_rsi = pd.Series(rolling_stoch_rsi, index=processed_series.index) \n",
    "        \n",
    "        # ======= IV. Change Name =======\n",
    "        rolling_stoch_rsi.name = f\"{self.name}_{window}_{smoothing_method}_{window_smooth}_{lambda_smooth}\"\n",
    "        rolling_stoch_rsi.index = data.index\n",
    "\n",
    "        return rolling_stoch_rsi\n",
    "\n",
    "#*_____________________________________________________________________________________ #\n",
    "def get_stochastic_rsi(\n",
    "    series: pd.Series\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Computes the Stochastic RSI for a given price series.\n",
    "    \n",
    "    Parameters:\n",
    "        - series (pd.Series): Price series to compute Stochastic RSI on.\n",
    "    \n",
    "    Returns:\n",
    "        - float: The Stochastic RSI value for the last point in the series.\n",
    "    \"\"\"\n",
    "    # ========== 0. Define a function to compute the Stochastic RSI =======\n",
    "    def get_relative_strength_index(\n",
    "        series: pd.Series\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Computes the Relative Strength Index (RSI) for a given price series.\n",
    "        \n",
    "        Parameters:\n",
    "            - series (pd.Series): Price series to compute RSI on.\n",
    "        \n",
    "        Returns:\n",
    "            - pd.Series: The RSI values for the input series.\n",
    "        \"\"\"\n",
    "        # ======= I. Compute Gain and Loss =======\n",
    "        delta = series.diff()\n",
    "        gain = delta.where(delta > 0, 0.0)\n",
    "        loss = -delta.where(delta < 0, 0.0)\n",
    "\n",
    "        # ======= II. Compute Average Gain and Loss =======\n",
    "        avg_gain = gain.rolling(window=len(series)).mean()\n",
    "        avg_loss = loss.rolling(window=len(series)).mean()\n",
    "\n",
    "        # ======= III. Compute Relative Strength and RSI =======\n",
    "        rs = avg_gain / (avg_loss + 1e-8)\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "\n",
    "        return rsi\n",
    "    \n",
    "    # ======= I. Compute the Relative Strength Index (RSI) =======\n",
    "    rsi = get_relative_strength_index(series)\n",
    "\n",
    "    # ======= II. Extract last few RSI values to get the range for StochRSI =======\n",
    "    rsi_values = rsi.dropna()\n",
    "    if len(rsi_values) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    last_rsi = rsi_values.iloc[-1]\n",
    "    min_rsi = rsi_values.min()\n",
    "    max_rsi = rsi_values.max()\n",
    "\n",
    "    # ======= III. Compute Stochastic RSI =======\n",
    "    stoch_rsi = (last_rsi - min_rsi) / (max_rsi - min_rsi + 1e-8)\n",
    "    \n",
    "    return stoch_rsi\n",
    "\n",
    "#!_____________________________________________________________________________________ #\n",
    "stochrsi_feature = Kama_feature(n_jobs=n_jobs)\n",
    "stochrsi_params = {\n",
    "    \"window\": [5, 10, 20, 50],\n",
    "    \"smoothing_method\": [None, 'ewma'],\n",
    "    \"window_smooth\": [5],\n",
    "    \"lambda_smooth\": [0.2],\n",
    "}\n",
    "stochrsi_feature.set_params(**stochrsi_params)\n",
    "\n",
    "stochrsi_feature_df = stochrsi_feature.extract(data=processed_train['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EhlersFisher_feature(Feature):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        name: str = \"ehlers_fisher\", \n",
    "        n_jobs: int = 1\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the Cointegration_feature object.\n",
    "\n",
    "        Parameters:\n",
    "            - name (str): Feature name.\n",
    "            - n_jobs (int): Number of parallel jobs to use.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "\n",
    "    #?____________________________________________________________________________________ #\n",
    "    def set_params(\n",
    "        self, \n",
    "        window: list = [5, 10, 30, 60], \n",
    "        smoothing_method: list = [None, \"ewma\", \"average\"], \n",
    "        window_smooth: list = [5, 10], \n",
    "        lambda_smooth: list = [0.1, 0.2, 0.5]\n",
    "    ) -> Self:\n",
    "        \"\"\"\n",
    "        Sets the parameter grid for cointegration feature extraction.\n",
    "\n",
    "        Parameters:\n",
    "            - window (list): Rolling window sizes for cointegration tests.\n",
    "            - smoothing_method (list): Smoothing method to apply before testing.\n",
    "            - window_smooth (list): Smoothing window sizes.\n",
    "            - lambda_smooth (list): Decay factors for EWMA smoothing.\n",
    "        \"\"\"\n",
    "        self.params = {\n",
    "            \"window\": window,\n",
    "            \"smoothing_method\": smoothing_method,\n",
    "            \"window_smooth\": window_smooth,\n",
    "            \"lambda_smooth\": lambda_smooth,\n",
    "        }\n",
    "        \n",
    "        return self\n",
    "\n",
    "    #?____________________________________________________________________________________ #\n",
    "    def process_data(\n",
    "        self, \n",
    "        data: Union[tuple, pd.DataFrame],\n",
    "    ) -> tuple:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # ======= I. Extract Series =======\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            nb_series = data.shape[1]\n",
    "            if nb_series != 2:\n",
    "                raise ValueError(f\"DataFrame must have exactly 2 columns, but got {nb_series}.\")\n",
    "            \n",
    "            series_high = data.iloc[:, 0]\n",
    "            series_low = data.iloc[:, 1]\n",
    "        \n",
    "        elif isinstance(data, tuple) and len(data) == 2:\n",
    "            series_high = data[0]\n",
    "            series_low = data[1]\n",
    "        else:\n",
    "            raise ValueError(\"Data must be either a tuple of two series or a DataFrame with two columns.\")\n",
    "        \n",
    "        # ======= II. Ensure Series have the same indexation =======\n",
    "        series_df = pd.DataFrame({\"series_high\": series_high, \"series_low\": series_low})\n",
    "        series_df = series_df.dropna()\n",
    "        series_high = series_df[\"series_high\"]\n",
    "        series_low = series_df[\"series_low\"]\n",
    "        \n",
    "        # ======= III. Return Processed Data =======    \n",
    "        processed_data = (series_high, series_low)\n",
    "\n",
    "        return processed_data\n",
    "\n",
    "    #?____________________________________________________________________________________ #\n",
    "    def get_feature(\n",
    "        self, \n",
    "        data: Union[tuple, pd.DataFrame],\n",
    "        window: int,\n",
    "        smoothing_method: str,\n",
    "        window_smooth: int,\n",
    "        lambda_smooth: float,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # ======= I. Process Data =======\n",
    "        processed_data = self.process_data(data=data)\n",
    "        series_high = processed_data[0]\n",
    "        series_low = processed_data[1]\n",
    "\n",
    "        # ======= II. Apply Smoothing if Needed =======\n",
    "        if smoothing_method is not None:\n",
    "            series_high = self.smooth_data(data=series_high, smoothing_method=smoothing_method, window_smooth=window_smooth, lambda_smooth=lambda_smooth)\n",
    "            series_low = self.smooth_data(data=series_low, smoothing_method=smoothing_method, window_smooth=window_smooth, lambda_smooth=lambda_smooth)\n",
    "\n",
    "        # ======= II. Ensure the window is not too large =======\n",
    "        num_obs = len(series_high) - window\n",
    "        if num_obs <= 0:\n",
    "            raise ValueError(f\"Window size {window} is too large for the given data length {len(series_high)}.\")\n",
    "        \n",
    "        # ======= III. Initialize Output Arrays =======\n",
    "        elhers_fisher_values = np.full(num_obs, np.nan)\n",
    "\n",
    "        # ======== IV. Iterate Over Observations ========\n",
    "        for i in range(num_obs):\n",
    "            # IV.1 Extract Time Windows\n",
    "            series_high_window = series_high.iloc[i : i + window]\n",
    "            series_low_window = series_low.iloc[i : i + window]\n",
    "\n",
    "            # IV.2 Perform Elhers Fisher transform Test\n",
    "            elhers_fisher = get_ehlers_fisher_transform(\n",
    "                series_high=series_high_window, \n",
    "                series_low=series_low_window\n",
    "            )\n",
    "\n",
    "            # IV.3 Store Results\n",
    "            elhers_fisher_values[i] = elhers_fisher\n",
    "\n",
    "        # ======== V. Create the Final DataFrame ========\n",
    "        index = series_high.index[window:]\n",
    "        features_df = pd.DataFrame({\n",
    "            f\"{self.name}_{window}_{smoothing_method}_{window_smooth}_{lambda_smooth}\": elhers_fisher_values,\n",
    "        }, index=index)\n",
    "\n",
    "        return features_df\n",
    "\n",
    "#*_____________________________________________________________________________________ #\n",
    "def get_ehlers_fisher_transform(\n",
    "    series_high: pd.Series, \n",
    "    series_low: pd.Series, \n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Computes the Ehlers Fisher Transform on a high-low price window.\n",
    "    Returns only the last transformed value.\n",
    "    \"\"\"\n",
    "    mid_series = (series_high + series_low) / 2\n",
    "\n",
    "    min_val = mid_series.min()\n",
    "    max_val = mid_series.max()\n",
    "    if max_val - min_val == 0:\n",
    "        return 0.0  # avoid division by zero\n",
    "\n",
    "    # Normalize entire series to [-1, 1]\n",
    "    normalized = 2 * ((mid_series - min_val) / (max_val - min_val)) - 1\n",
    "    normalized = np.clip(normalized, -0.999, 0.999)\n",
    "\n",
    "    # Apply Fisher Transform\n",
    "    fisher = 0.5 * np.log((1 + normalized) / (1 - normalized))\n",
    "\n",
    "    return fisher.iloc[-1]  # Only return the last value\n",
    "\n",
    "#!_____________________________________________________________________________________ #\n",
    "ehlers_fisher_feature = EhlersFisher_feature(n_jobs=n_jobs)\n",
    "ehlers_fisher_params = {\n",
    "    \"window\": [5, 10, 20, 50],\n",
    "    \"smoothing_method\": [None, 'ewma'],\n",
    "    \"window_smooth\": [5],\n",
    "    \"lambda_smooth\": [0.2],\n",
    "}\n",
    "ehlers_fisher_feature.set_params(**ehlers_fisher_params)\n",
    "\n",
    "ehlers_fisher_feature_df = ehlers_fisher_feature.extract(data=processed_train[['high', 'low']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
